<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>小生很忙</title>
    <link>https://chaoge123456.github.io/</link>
    <atom:link href="/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>网络安全和机器学习相关技术分享</description>
    <pubDate>Sun, 21 Oct 2018 16:18:12 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>维吉尼亚加解密及唯密文破解</title>
      <link>https://chaoge123456.github.io/%E7%BB%B4%E5%90%89%E5%B0%BC%E4%BA%9A%E5%8A%A0%E8%A7%A3%E5%AF%86%E5%8F%8A%E5%94%AF%E5%AF%86%E6%96%87%E7%A0%B4%E8%A7%A3.html/</link>
      <guid>https://chaoge123456.github.io/%E7%BB%B4%E5%90%89%E5%B0%BC%E4%BA%9A%E5%8A%A0%E8%A7%A3%E5%AF%86%E5%8F%8A%E5%94%AF%E5%AF%86%E6%96%87%E7%A0%B4%E8%A7%A3.html/</guid>
      <pubDate>Wed, 17 Oct 2018 02:10:22 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt; 古典密码体制主要通过字符间的置换和代换来实现，常见的置换密码包括列置换密码和周期置换密码，而常见的代换密码包括单表代换密码和多表代换密码，本文所讨论的维吉尼亚算法是属于多表代换密码的一种。多表代换密码是以一系列代换表依次对明文消息的字
        
      
      </description>
      
      <content:encoded><![CDATA[<p><strong>摘要</strong> 古典密码体制主要通过字符间的置换和代换来实现，常见的置换密码包括列置换密码和周期置换密码，而常见的代换密码包括单表代换密码和多表代换密码，本文所讨论的维吉尼亚算法是属于多表代换密码的一种。多表代换密码是以一系列代换表依次对明文消息的字母序列进行代换的加密方法，即明文消息中出现的同一个字母，在加密时不是完全被同一固定的字母代换，而是根据其出现的位置次序用不同的字母代换。如果代换表序列是非周期的无限序列，则相应的密码称为非周期多表代换密码，这类密码对每个明文都采用了不同的代换表进行加密，故称为一次一密密码，它是理论上不可破译的密码体制。但实际应用中经常采用的是周期多表代换密码，它通常使用有限个代换表，代换表被重复使用以完成消息的加密。作为多表代换密码的典型代表，维吉尼亚密码算法蕴含着丰富的古典密码设计思想，本文将深入探讨维吉尼亚算法的加解密过程实现，以及利用统计分析的方法进行唯密文攻击。</p><img src="http://pcvm1j2f3.bkt.clouddn.com/static/images/verify/crypt.jpg?imageView2/2/w/600">  <h2 id="文章概览"><a href="#文章概览" class="headerlink" title="文章概览"></a>文章概览</h2><ul><li>维吉尼亚算法简介</li><li>加密算法实现<ul><li>编码方式</li><li>对明文进行处理</li><li>加密过程</li></ul></li><li>解密算法实现</li><li>唯密文攻击<ul><li>确定密钥长度</li><li>确定密钥</li><li>恢复明文</li></ul></li></ul><h3 id="维吉尼亚算法简介"><a href="#维吉尼亚算法简介" class="headerlink" title="维吉尼亚算法简介"></a><a href="#https://zh.wikipedia.org/wiki/%E7%BB%B4%E5%90%89%E5%B0%BC%E4%BA%9A%E5%AF%86%E7%A0%81">维吉尼亚算法简介</a></h3><h3 id="加密算法实现"><a href="#加密算法实现" class="headerlink" title="加密算法实现"></a>加密算法实现</h3><p>&emsp;&emsp;实现加密算法的大致流程是：首先我们需要确定编码方式，本文采用的编码方式是[a-z]对应[0-25]；接着进行加密算法前需要对明文字符串进行处理，删除非字母字符，将大写字符统一转换为小写字母；最后选定密钥对密文中的逐个字符进行加密（即代换操作），生成最后的密文。</p><h4 id="编码方式"><a href="#编码方式" class="headerlink" title="编码方式"></a>编码方式</h4><p>&emsp;&emsp;本文的字母编码方式由列表s确定，s中每个元素的索引即对应该元素的数字编码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s = [<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>,<span class="string">'e'</span>,<span class="string">'f'</span>,<span class="string">'g'</span>,<span class="string">'h'</span>,<span class="string">'i'</span>,<span class="string">'j'</span>,<span class="string">'k'</span>,<span class="string">'l'</span>,<span class="string">'m'</span>,<span class="string">'n'</span>,<span class="string">'o'</span>,<span class="string">'p'</span>,<span class="string">'q'</span>,<span class="string">'r'</span>,<span class="string">'s'</span>,<span class="string">'t'</span>,<span class="string">'u'</span>,<span class="string">'v'</span>,<span class="string">'w'</span>,<span class="string">'x'</span>,<span class="string">'y'</span>,<span class="string">'z'</span>]</span><br></pre></td></tr></table></figure><h4 id="对明文进行处理"><a href="#对明文进行处理" class="headerlink" title="对明文进行处理"></a>对明文进行处理</h4><p>&emsp;&emsp;对明文进行处理的目的是去除明文中非字母的字符，并将大写字母统一转换为小写字母。转换大小写我们可以使用python字符串内置的lower()函数，稍微有点棘手的是前者，因为在这里需要考虑到一些效率的问题还有如何对后续操作进行优化的问题，比如说:</p><ul><li>读取文件中的明文时我们可以采用read()，readline()，readlines()这三个函数，那我们到底采用哪一个呢？（这三个函数的对比可以参考<a href="#https://blog.csdn.net/quiet_girl/article/details/80113591">这篇博客</a>)</li><li>采用不同读取明文的函数，导致读取结果也不尽相同，有列表形式也有字符串形式，到底哪种形式对后续的操作更有好处</li><li>去掉读取后的明文中的非字母字符应采用何种方式？（逐个字符判断或者正则表达式）</li></ul><p>本文根据文本的实际情况，采用的处理方式如下所示</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pretreatment</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    pretreatment函数的主要作用是对明文进行预处理，去除非字母字符和转换大小写</span></span><br><span class="line"><span class="string">    :return: 经过预处理的明文字符串</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">"plain.txt"</span>,<span class="string">"r"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        wen = f.read()</span><br><span class="line">    pattern = re.compile(<span class="string">'[\n]|\d|\W'</span>)</span><br><span class="line">    plain_1 = re.sub(pattern,<span class="string">''</span>,wen).lower()</span><br><span class="line">    <span class="keyword">return</span> plain_1</span><br></pre></td></tr></table></figure><h4 id="加密过程"><a href="#加密过程" class="headerlink" title="加密过程"></a>加密过程</h4><p>&emsp;&emsp;维吉尼亚算法的加密过程比较简单，基本思想是利用密钥循环对明文字符进行代换操作，进行代换前将相应的明文字符和密钥字符转化为对应的数字编码，然后相加对26取余即得到对应的密文字符。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">encrypt</span><span class="params">(key)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    encrypt函数的主要作用是进行加密</span></span><br><span class="line"><span class="string">    :param key: 密钥</span></span><br><span class="line"><span class="string">    :return: 密文字符串</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    wen = pretreatment()</span><br><span class="line">    num_key = key_to_num(key)</span><br><span class="line">    ciphertext = <span class="string">''</span></span><br><span class="line">    k = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> wen:</span><br><span class="line">        <span class="keyword">if</span> k == len(num_key):</span><br><span class="line">            k = <span class="number">0</span></span><br><span class="line">        cipher = change(w,num_key[k])</span><br><span class="line">        cipher = num_to_char(cipher)</span><br><span class="line">        ciphertext = ciphertext + cipher</span><br><span class="line">        k += <span class="number">1</span></span><br><span class="line">    wirte_txt(ciphertext,<span class="string">'crypt.txt'</span>)</span><br><span class="line">    <span class="keyword">return</span> ciphertext</span><br></pre></td></tr></table></figure><h3 id="解密算法实现"><a href="#解密算法实现" class="headerlink" title="解密算法实现"></a>解密算法实现</h3><p>&emsp;&emsp;解密算法是加密算法的逆过程，进行的代换操作是将密文字符的数字编码减去密钥字符的数字编码，如果相减的结果小于0，则令结果加上26，在转换为对应编码的字符。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">de_change</span><span class="params">(ch,num)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    de_change函数的作用是根据密文字符和密钥还原明文字符</span></span><br><span class="line"><span class="string">    :param ch: 密文字符</span></span><br><span class="line"><span class="string">    :param num: 密钥编码</span></span><br><span class="line"><span class="string">    :return: 明文字符</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    ch_num = char_to_num(ch)</span><br><span class="line">    result = ch_num - num</span><br><span class="line">    <span class="keyword">if</span> result &lt; <span class="number">0</span>:</span><br><span class="line">        result = <span class="number">26</span> + result</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">decrypt</span><span class="params">(key)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    decryption函数的主要作用是将密文解密成明文</span></span><br><span class="line"><span class="string">    :param key: 密钥</span></span><br><span class="line"><span class="string">    :return: 明文</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'crypt.txt'</span>,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        ciphertext = f.read()</span><br><span class="line">    num_key = key_to_num(key)</span><br><span class="line">    wen = <span class="string">''</span></span><br><span class="line">    k = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> ciphertext:</span><br><span class="line">        <span class="keyword">if</span> k == len(num_key):</span><br><span class="line">            k = <span class="number">0</span></span><br><span class="line">        w = de_change(c,num_key[k])</span><br><span class="line">        w = num_to_char(w)</span><br><span class="line">        wen = wen + w</span><br><span class="line">        k += <span class="number">1</span></span><br><span class="line">    wirte_txt(wen,<span class="string">'result.txt'</span>)</span><br><span class="line">    <span class="keyword">return</span> wen</span><br></pre></td></tr></table></figure><h3 id="唯密文攻击"><a href="#唯密文攻击" class="headerlink" title="唯密文攻击"></a>唯密文攻击</h3><p>&emsp;&emsp;某种语言中各个字符出现的频率不一样而表现出一定的统计规律，而这种统计规律可能在密文中重现，所以我们可以通过统计分析的手段进行一些推测和验证过程来实现对密文的分析。在英文字母中各个字母出现的频率如下所示，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#编码规则</span></span><br><span class="line">s = [<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>,<span class="string">'e'</span>,<span class="string">'f'</span>,<span class="string">'g'</span>,<span class="string">'h'</span>,<span class="string">'i'</span>,<span class="string">'j'</span>,<span class="string">'k'</span>,<span class="string">'l'</span>,<span class="string">'m'</span>,<span class="string">'n'</span>,<span class="string">'o'</span>,<span class="string">'p'</span>,<span class="string">'q'</span>,<span class="string">'r'</span>,<span class="string">'s'</span>,<span class="string">'t'</span>,<span class="string">'u'</span>,<span class="string">'v'</span>,<span class="string">'w'</span>,<span class="string">'x'</span>,<span class="string">'y'</span>,<span class="string">'z'</span>]</span><br><span class="line"><span class="comment">#字母出现频率</span></span><br><span class="line">frequency = [<span class="number">0.082</span>,<span class="number">0.015</span>,<span class="number">0.028</span>,<span class="number">0.043</span>,<span class="number">0.127</span>,<span class="number">0.022</span>,<span class="number">0.02</span>,<span class="number">0.061</span>,<span class="number">0.07</span>,<span class="number">0.002</span>,<span class="number">0.008</span>,<span class="number">0.04</span>,<span class="number">0.024</span>,<span class="number">0.06</span>,<span class="number">0.075</span>,<span class="number">0.019</span>,<span class="number">0.001</span>,<span class="number">0.06</span>,<span class="number">0.063</span>,<span class="number">0.091</span>,<span class="number">0.028</span>,<span class="number">0.01</span>,<span class="number">0.023</span>,<span class="number">0.001</span>,<span class="number">0.02</span>,<span class="number">0.001</span>]</span><br></pre></td></tr></table></figure><p>对于维吉尼亚密码体制来说，我们可以通过统计分析的方法对其密文进行分析，从而获取明文信息。基于维吉尼亚密码体制的唯密文攻击的破解主要包含三个步骤：</p><ul><li>确定密钥长度，常用的方法包括卡西斯基测试法和重合指数法，本文将采用后者进行分析</li><li>确定密钥，常用的方法是拟重合指数法</li><li>根据密文和密钥恢复明文</li></ul><h4 id="确定密钥长度"><a href="#确定密钥长度" class="headerlink" title="确定密钥长度"></a>确定密钥长度</h4><p>&emsp;&emsp;本文采用重合指数法猜解密钥长度，关于重合指数法的具体解释可以参照《现代密码学教程》或者<a href="#https://zh.wikipedia.org/wiki/%E7%BB%B4%E5%90%89%E5%B0%BC%E4%BA%9A%E5%AF%86%E7%A0%81">维基百科</a>，本文主要讲解猜解密钥长度的实现过程。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">guess_len_key</span><span class="params">(crypt)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    guess_len_key函数的主要作用是通过密文猜解密钥长度</span></span><br><span class="line"><span class="string">    :param crypt: 密文</span></span><br><span class="line"><span class="string">    :return: 密钥长度以及划为的子串</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    l = <span class="number">1</span></span><br><span class="line">    d = &#123;&#125;</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        print(<span class="string">"****************************假设密钥长度        为%s***********************************"</span> % l)</span><br><span class="line">        sum_index = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(crypt)):</span><br><span class="line">            n = i % l</span><br><span class="line">            <span class="keyword">if</span> n <span class="keyword">not</span> <span class="keyword">in</span> d:</span><br><span class="line">                d[n] = <span class="string">''</span></span><br><span class="line">            d[n] += crypt[i]</span><br><span class="line">        sum_index = sum(coincidence_index(d[j]) <span class="keyword">for</span> j <span class="keyword">in</span> range(l)) / l</span><br><span class="line">        <span class="keyword">if</span> sum_index &gt;= <span class="number">0.06</span> <span class="keyword">and</span> sum_index &lt;= <span class="number">0.07</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            l += <span class="number">1</span></span><br><span class="line">            d = &#123;&#125;</span><br><span class="line">    <span class="keyword">return</span> l,d</span><br></pre></td></tr></table></figure><p>该算法的主要思想是将密文划分为l个子串，子串存放在字典d中。分别计算l个子串的重合指数，然后计算l个重合指数的平均数，如果该平均数位于[0.06,0.07]这个区间内，则说明密钥长度为l，返回密钥长度以及划分的l个子串；如果得到的平均数不在[0.06,0.07]这个区间内，则l自增，d初始化，进行下一轮猜解。</p><h4 id="确定密钥"><a href="#确定密钥" class="headerlink" title="确定密钥"></a>确定密钥</h4><p>&emsp;&emsp;确定密钥长度大致过程是：利用之前得到的l个子串，对每个子串都进行移位操作。假设现在对第i个子串进行移位操作（子串的每个字符移动相同的位数，最坏情况下对同一个子串需要进行26次移位操作），移动的位数为k,（k在[0-25]区间内，也就对应了[a-z]）。每进行一次移位操作，就对该子串计算一次拟重合指数，如果该拟重合指数位于[0.06,0.07]这个区间内，则说明此时移动的位数对应的s列表中的字符即为该子串的密钥；否则，继续进行下一次移位操作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">crack_key</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    cracker函数的主要作用是破解密钥</span></span><br><span class="line"><span class="string">    :return: 返回密钥</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">"crypt.txt"</span>,<span class="string">"r"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        crypt = f.read()</span><br><span class="line">    len_key,d = guess_len_key(crypt)</span><br><span class="line">    key = <span class="string">''</span></span><br><span class="line">    print(<span class="string">"\n-------------------------------------"</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"|       经计算可知，密钥长度为%s         |"</span> % len_key)</span><br><span class="line">    print(<span class="string">"-------------------------------------\n"</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len_key):</span><br><span class="line">        substring = d[i]</span><br><span class="line">        print(<span class="string">"当前字串为："</span>,d[i])</span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> range(<span class="number">26</span>):</span><br><span class="line">            dex = quasi_index(substring, n)</span><br><span class="line">            print(<span class="string">"假设子串移动&#123;&#125;,拟重合指数为&#123;:.4f&#125;"</span>.format(s[n],dex))</span><br><span class="line">            <span class="keyword">if</span> dex &gt;= <span class="number">0.06</span> <span class="keyword">and</span> dex &lt;= <span class="number">0.07</span>:</span><br><span class="line">                key += s[n]</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">    print(<span class="string">"******************************破解的最终密钥为%s*********************************"</span> % key)</span><br></pre></td></tr></table></figure><h4 id="恢复明文"><a href="#恢复明文" class="headerlink" title="恢复明文"></a>恢复明文</h4><p>&emsp;&emsp;恢复明文的过程与解密过程类似，这里不在详述。</p><h3 id="系统运行演示"><a href="#系统运行演示" class="headerlink" title="系统运行演示"></a>系统运行演示</h3><h4 id="加密"><a href="#加密" class="headerlink" title="加密"></a>加密</h4><img src="http://pcvm1j2f3.bkt.clouddn.com/static/images/verify/jiami.PNG?imageView2/2/w/600">  <h4 id="解密"><a href="#解密" class="headerlink" title="解密"></a>解密</h4><img src="http://pcvm1j2f3.bkt.clouddn.com/static/images/verify/jiemi.PNG?imageView2/2/w/600">  <h4 id="猜解密钥长度"><a href="#猜解密钥长度" class="headerlink" title="猜解密钥长度"></a>猜解密钥长度</h4><img src="http://pcvm1j2f3.bkt.clouddn.com/static/images/verify/keylen.PNG?imageView2/2/w/600">  <h4 id="猜解密钥"><a href="#猜解密钥" class="headerlink" title="猜解密钥"></a>猜解密钥</h4><img src="http://pcvm1j2f3.bkt.clouddn.com/static/images/verify/nichonghe.PNG?imageView2/2/w/600">  ]]></content:encoded>
      
      <comments>https://chaoge123456.github.io/%E7%BB%B4%E5%90%89%E5%B0%BC%E4%BA%9A%E5%8A%A0%E8%A7%A3%E5%AF%86%E5%8F%8A%E5%94%AF%E5%AF%86%E6%96%87%E7%A0%B4%E8%A7%A3.html/#disqus_thread</comments>
    </item>
    
    <item>
      <title>raspberry入门配置</title>
      <link>https://chaoge123456.github.io/raspberry%E5%85%A5%E9%97%A8%E9%85%8D%E7%BD%AE.html/</link>
      <guid>https://chaoge123456.github.io/raspberry%E5%85%A5%E9%97%A8%E9%85%8D%E7%BD%AE.html/</guid>
      <pubDate>Sat, 22 Sep 2018 12:53:38 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt; 最近准备在树莓派上搭建一个智能家居系统，更新系统的过程中不知道什么原因导致系统崩了，我的心顿时凉了半截。查阅了很多资料，没找到解决方法，只能重装系统（基于stretch版本）了。虽然之前的系统也是自己一步步配置的，但是这次重新配置的过
        
      
      </description>
      
      <content:encoded><![CDATA[<p><strong>摘要</strong> 最近准备在树莓派上搭建一个智能家居系统，更新系统的过程中不知道什么原因导致系统崩了，我的心顿时凉了半截。查阅了很多资料，没找到解决方法，只能重装系统（基于stretch版本）了。虽然之前的系统也是自己一步步配置的，但是这次重新配置的过程中还是遇到了很多问题，在这里记录一下，希望能给小伙伴们一些启发。</p><img src="http://pcvm1j2f3.bkt.clouddn.com/static/images/raspberry/images.png?imageView2/2/w/600">  <h2 id="文章概览"><a href="#文章概览" class="headerlink" title="文章概览"></a>文章概览</h2><ul><li>重新安装系统</li><li>连接树莓派</li><li>安装远程桌面服务</li><li>更新软件源</li><li>raspi-config</li><li>配置无线网络</li><li>配置静态IP</li><li>配置内网映射</li><li>安装zsh</li><li>python环境搭建</li></ul><h3 id="重新安装系统"><a href="#重新安装系统" class="headerlink" title="重新安装系统"></a>重新安装系统</h3><p>&emsp;&emsp;重新安装系统的过程我们需要用到：<a href="#https://www.raspberrypi.org/downloads/">系统镜像</a>、<a href="#http://www.diskgenius.cn/">DiskGenius</a>、<a href="#https://sourceforge.net/projects/win32diskimager/">Win32DiskImager</a>，DiskGenius的作用是格式化TF卡，Win32DiskImager的作用是将系统镜像写入TF卡，具体的操作过程可以参考<a href="#https://www.jianshu.com/p/6af60049fdf1">这篇博客</a>。</p><h3 id="连接树莓派"><a href="#连接树莓派" class="headerlink" title="连接树莓派"></a>连接树莓派</h3><p>&emsp;&emsp;对于如何连接树莓派，我在之前的博客中详细的讨论过，这里不再赘述，需要提醒大家的是只需要使用某一种方法连接树莓派即可。</p><h3 id="安装远程连接服务"><a href="#安装远程连接服务" class="headerlink" title="安装远程连接服务"></a>安装远程连接服务</h3><p>&emsp;&emsp;ssh连接是通过命令行对树莓派进行远程操作，而远程桌面是直接通过树莓派的GUI界面进行操作，操作简单，交互性好。xrdp是一个开源的远程桌面服务器，支持windows远程桌面连接，但是需要使用tightvncserver作为其基础服务，具体安装操作如下所示。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update #更新</span><br><span class="line">sudo apt-get install xrdp</span><br><span class="line">sudo apt-get install tightvncserver</span><br></pre></td></tr></table></figure><p>安装好以上两个服务以后。可以使用windows自带的远程连接工具连接到树莓派。</p><h3 id="更新软件源"><a href="#更新软件源" class="headerlink" title="更新软件源"></a>更新软件源</h3><p>&emsp;&emsp;在更新软件源的时候，大家注意查看自己的系统版本（推荐大家安装最新的系统版本），具体操作参见<a href="#https://mirror.tuna.tsinghua.edu.cn/help/">清华大学开源软件镜像站</a>。</p><h3 id="raspi-config"><a href="#raspi-config" class="headerlink" title="raspi-config"></a>raspi-config</h3><p>&emsp;&emsp;通过远程桌面连接到树莓派之后，系统会提示进行一些初始化配置，包括拓展内存、设置时区、语言等等，具体操作参见<a href="#http://shumeipai.nxez.com/2013/09/07/raspi-config-configuration-raspberry-pie.html">这篇博客</a>。</p><h3 id="配置无线网络"><a href="#配置无线网络" class="headerlink" title="配置无线网络"></a>配置无线网络</h3><p>&emsp;&emsp;配置无线网络有两种方式，一个是在图形化界面直接选择连接的ssid，输入密码即可，系统会保存该无线网络的相关信息到/etc/wpa_supplicant/wpa_supplicant.conf文件；另外一种方式是直接修改该配置文件，将无线网络配置信息添加到该文件中。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">country=CN</span><br><span class="line">ctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev</span><br><span class="line">update_config=1</span><br><span class="line"></span><br><span class="line">network=&#123;</span><br><span class="line">    ssid="***"</span><br><span class="line">    psk="***"</span><br><span class="line">    priority=1</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h3 id="配置静态IP"><a href="#配置静态IP" class="headerlink" title="配置静态IP"></a>配置静态IP</h3><p>&emsp;&emsp;由于每次树莓派连接路由器的时候，路由器会分配不同的IP地址，所以当我们连接树莓派的时候每次都要通过路由器查看树莓派的IP地址，这样比较麻烦，所以，我们需要给路由器指定静态的IP。修改/etc/dhcpcd.conf文件（一定要注意不是修改/etc/network/interfaces文件），在后面添加以下内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">interface eth0 #有线</span><br><span class="line"> </span><br><span class="line">static ip_address=192.168.0.10/24</span><br><span class="line">static routers=192.168.0.1</span><br><span class="line">static domain_name_servers=192.168.0.1</span><br><span class="line"> </span><br><span class="line">interface wlan0 #无线连接</span><br><span class="line"> </span><br><span class="line">static ip_address=192.168.0.200/24</span><br><span class="line">static routers=192.168.0.1</span><br><span class="line">static domain_name_servers=192.168.0.1</span><br></pre></td></tr></table></figure><h3 id="配置内网映射"><a href="#配置内网映射" class="headerlink" title="配置内网映射"></a>配置内网映射</h3><p>&emsp;&emsp;如果想要从外网直接访问树莓派，那我们需要将树莓派的内网IP映射到公网当中，这里我们使用的映射工具是花生壳，具体操作参见<a href="#http://service.oray.com/question/2680.html">官方教程</a>。</p><h3 id="安装zsh"><a href="#安装zsh" class="headerlink" title="安装zsh"></a>安装zsh</h3><p>&emsp;&emsp;树莓派基于linux操作系统，其终端shell默认的是bash，而zsh是比bash更加强大的shell，而且更加美观，具体配置参见<a href="#https://mlapp.cn/310.html">这篇博客</a>。</p><h3 id="python环境搭建"><a href="#python环境搭建" class="headerlink" title="python环境搭建"></a>python环境搭建</h3><p>&emsp;&emsp;树莓派中内置了两个版本的python，python2.7和python3.5，系统默认版本为python2.7。在进行系统环境配置和相关依赖安装的过程中，一律使用系统默认版本即python2.7（如果切换至python3.5.会出现各种各样的问题）。在程序开发过程中如果需要使用python3.5，可以切换python环境，具体操作参见<a href="#https://linux.cn/article-6970-1.html">这篇博客</a>。</p>]]></content:encoded>
      
      <comments>https://chaoge123456.github.io/raspberry%E5%85%A5%E9%97%A8%E9%85%8D%E7%BD%AE.html/#disqus_thread</comments>
    </item>
    
    <item>
      <title>如何连接树莓派</title>
      <link>https://chaoge123456.github.io/%E5%A6%82%E4%BD%95%E8%BF%9E%E6%8E%A5%E6%A0%91%E8%8E%93%E6%B4%BE.html/</link>
      <guid>https://chaoge123456.github.io/%E5%A6%82%E4%BD%95%E8%BF%9E%E6%8E%A5%E6%A0%91%E8%8E%93%E6%B4%BE.html/</guid>
      <pubDate>Thu, 13 Sep 2018 12:08:02 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt; 早就听说了树莓派的大名，什么智能家居，智能机器人，无人机等等它都不在话下。我最近刚刚入手了一款树莓派3B+，想利用它来开发一个智能家居的控制系统。由于从来没有接触过相关的硬件，在配置过程中确实遇到了不少坑，在这里简单的记录一下，希望能
        
      
      </description>
      
      <content:encoded><![CDATA[<p><strong>摘要</strong> 早就听说了树莓派的大名，什么智能家居，智能机器人，无人机等等它都不在话下。我最近刚刚入手了一款树莓派3B+，想利用它来开发一个智能家居的控制系统。由于从来没有接触过相关的硬件，在配置过程中确实遇到了不少坑，在这里简单的记录一下，希望能给读者一些启发。本文主要讲解如何连接树莓派的问题。</p><img src="http://pcvm1j2f3.bkt.clouddn.com/static/images/raspberry/shumei.jpg?imageView2/2/w/600"><h2 id="文章概览"><a href="#文章概览" class="headerlink" title="文章概览"></a>文章概览</h2><ul><li>基本配置</li><li>系统安装</li><li>连接树莓派<ul><li>有路由器和网线的情况下</li><li>有网线没有路由器的情况下</li><li>没有路由器没有网线的情况下</li></ul></li></ul><h3 id="基本配置"><a href="#基本配置" class="headerlink" title="基本配置"></a>基本配置</h3><p>&emsp;&emsp;想要玩树莓派，仅仅买一块主板是不够的，基本的配置包括：一块主板（大概225RMB）、一个读卡器（大概10RMB）、一根电源线（大概8RMB）、一张大于8G的内存卡（我买的是32G的，38RMB）、散热片（大概5RMB）和一个保护外壳（大概20RMB），推荐大家主板和配件分开买，这样比较划算。</p><h3 id="系统安装"><a href="#系统安装" class="headerlink" title="系统安装"></a>系统安装</h3><p>&emsp;&emsp;树莓派的安装过程比较简单，首先我们需要下载准备安装的系统镜像，在<a href="#https://www.raspberrypi.org/downloads/">树莓派官网</a>可以下载到相关的镜像文件，树莓派支持的系统很多，包括ubuntu、kail、win10等等。我选择的系统是树莓派官方推荐的RSAPBIAN，基于Debian，稳定兼容性好。然后我们需要下载一款工具：<a href="#http://sourceforge.net/projects/win32diskimager/files/latest/download">win32diskimager</a>，我们需要利用这款工具将树莓派的系统镜像写入内存卡。</p><p>&emsp;&emsp;准备工作完成后，我们通过读卡器将内存卡接入电脑，在利用win32diskmager工具将系统镜像写入内存卡（这个过程很简单，这里不再详细解释）。镜像写入完成之后，我们的系统就成功的安装到内存卡中。但是，有一个问题需要我们注意，镜像写入完成后系统会弹出一个对话框，大概的意思是：无法识别内存卡中的数据，是否要将内存卡格式化，这个时候大家一定选择否或者直接关闭对话框。因为系统写入完成之后，我们的主机只能读出内存卡中系统的boot分区（大概只有40多MB），内存卡中的其他分区我们的系统识别不出来，所以才会弹出这个对话框，一旦我们选择格式化，刚才安装的系统会被删除。如果有小伙伴不小心选择了格式化，那就只有重新安装系统了，大家可以参考<a href="#https://www.jianshu.com/p/6af60049fdf1">这篇博客</a>。</p><p>&emsp;&emsp;还有一个需要注意的问题是，树莓派默认没有开启ssh服务，所以之后我们如果需要通过ssh连接树莓派时，我们需要在刚刚写入系统的内存卡的boot文件夹下，建立一个文件名为ssh的空文件（无后缀名），这样在之后的操作中我们就能通过ssh连接树莓派。</p><h3 id="连接树莓派"><a href="#连接树莓派" class="headerlink" title="连接树莓派"></a>连接树莓派</h3><p>&emsp;&emsp;连接树莓派最简单的方法就是通过HDMI数据线连接显示屏，这样我们可以直接通过显示屏对树莓派进行操作。那如果我们没有显示屏，我们该如何连接树莓派呢？</p><h4 id="有路由器和网线的情况下"><a href="#有路由器和网线的情况下" class="headerlink" title="有路由器和网线的情况下"></a>有路由器和网线的情况下</h4><p>&emsp;&emsp;这种情况下连接树莓派也比较简单，我们只需要将网线的一端接入路由器的lan接口，一端接入树莓派的网络接口（树莓派会自动获取IP地址），同时我们的主机也连接在路由器所建立的局域网内，此时我们可以通过路由器查看树莓派的IP地址。获取树莓派IP地址之后，我们通过主机中的xshell或者putty等远程连接工具就可以连接到树莓派。</p><h4 id="有网线没有路由器的情况下"><a href="#有网线没有路由器的情况下" class="headerlink" title="有网线没有路由器的情况下"></a>有网线没有路由器的情况下</h4><p>&emsp;&emsp;没有了路由器，树莓派就不能获取到IP地址，这种情况稍微复杂一点。解决办法是：将网线的两端连接树莓派和主机，然后我们打开主机的网络和共享中心</p><img src="http://pcvm1j2f3.bkt.clouddn.com/static/images/raspberry/1.PNG?imageView2/2/w/600"><p>点击我们已经连接的网络，查看其属性</p><img src="http://pcvm1j2f3.bkt.clouddn.com/static/images/raspberry/2.PNG?imageView2/2/w/600"><p>点击共享按钮，勾选允许其他网络用户通过此计算机的Internet连接来连接（N）</p><img src="http://pcvm1j2f3.bkt.clouddn.com/static/images/raspberry/3.PNG?imageView2/2/w/600"><p>接下来我们回到网络和共享中心，点击未识别的网络那一栏对于的以太网选项，查看其详细信息，可以看到其IP地址，这里的IP为192.168.137.1</p><img src="http://pcvm1j2f3.bkt.clouddn.com/static/images/raspberry/4.PNG?imageView2/2/w/600"><p>然后我们拔掉网线，关掉树莓派，拔出内存卡，将其通过读卡器连接到主机上。我们进入内存卡的boot文件夹，修改comline.txt文件，将 ip = 192.168.137.100 这句话添加到开头。完成上述步骤之后，我们将内存卡插入树莓派，用网线重新连接树莓派和主机，启动树莓派电源。我们通过远程连接工具连接树莓派，此时树莓派的IP地址为刚才设置的192.168.137.100，不出意外的话，我们也能连接上树莓派。</p><h4 id="没有路由器没有网线的情况下"><a href="#没有路由器没有网线的情况下" class="headerlink" title="没有路由器没有网线的情况下"></a>没有路由器没有网线的情况下</h4><p>&emsp;&emsp;要使我们的主机能够远程连接到树莓派上，我们必须满足一个条件：主机和树莓派位于同一个局域网。没有路由器和网线的情况下，我们可以通过手机热点建立一个局域网环境，让树莓派和主机同时连接手机热点。现在需要解决的问题是如何才能让树莓派连接上手机的热点。开机状态下，树莓派的无线模块一直处于工作状态，我们需要将无线热点的相关配置文件写入系统。同样，我们通过读卡器读取内存卡boot文件夹，在文件夹下新建文件名为wpa_supplicant.conf的文件，在文件内写入手机热点的配置信息并保存。</p><img src="http://pcvm1j2f3.bkt.clouddn.com/static/images/raspberry/5.PNG?imageView2/2/w/600"><p>然后重新插入内存卡，开启树莓派，在手机上查看树莓派的IP地址，用远程连接工具进行连接。</p>]]></content:encoded>
      
      <comments>https://chaoge123456.github.io/%E5%A6%82%E4%BD%95%E8%BF%9E%E6%8E%A5%E6%A0%91%E8%8E%93%E6%B4%BE.html/#disqus_thread</comments>
    </item>
    
    <item>
      <title>解释型语言python</title>
      <link>https://chaoge123456.github.io/%E8%A7%A3%E9%87%8A%E5%9E%8B%E8%AF%AD%E8%A8%80python.html/</link>
      <guid>https://chaoge123456.github.io/%E8%A7%A3%E9%87%8A%E5%9E%8B%E8%AF%AD%E8%A8%80python.html/</guid>
      <pubDate>Mon, 10 Sep 2018 15:14:35 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt; 计算机不能直接理解高级语言，只能直接理解机器语言，所以必须要把高级语言翻译成机器语言，计算机才能执行高级语言编写的程序。由于翻译方式的不同，习惯上我们大致把高级语言分为两类，即编译型语言和解释型语言。对于这两种类型的编程语言，很多人在
        
      
      </description>
      
      <content:encoded><![CDATA[<p><strong>摘要</strong> 计算机不能直接理解高级语言，只能直接理解机器语言，所以必须要把高级语言翻译成机器语言，计算机才能执行高级语言编写的程序。由于翻译方式的不同，习惯上我们大致把高级语言分为两类，即编译型语言和解释型语言。对于这两种类型的编程语言，很多人在理解层面上存在盲点，本文将对这两种类型的编程语言进行探讨，帮助读者更好的理解这一问题。</p><h2 id="文章概览"><a href="#文章概览" class="headerlink" title="文章概览"></a>文章概览</h2><ul><li><p>编译型语言和解释型语言</p><ul><li>基本解释</li><li>优缺点</li></ul></li><li><p>python</p><ul><li>python解释器</li><li>python代码执行过程</li></ul></li></ul><h3 id="编译型语言和解释型语言"><a href="#编译型语言和解释型语言" class="headerlink" title="编译型语言和解释型语言"></a>编译型语言和解释型语言</h3><h4 id="基本解释"><a href="#基本解释" class="headerlink" title="基本解释"></a>基本解释</h4><p>&emsp;&emsp;对于编译型语言，我们以C语言为例，C语言在执行过程中，先要将源程序编译为目标文件（机器代码），该目标文件是与平台相关的，也就是说ARM生成的目标文件，不能被用于MIPS的CPU，也不能用于x86的CPU。目标文件经过连接操作就可以生成可执行文件，以后我们想再次运行这段代码时，不必进行编译操作，只需要直接执行生成的可执行文件即可。</p><p>&emsp;&emsp;对于解释型语言呢，我们不需要执行编译过程，程序在执行时直接由解释器逐句地对程序进行解释，转换为机器可以执行的代码。但是对于有些解释型语言来说，也需要进行编译操作，比如Java。Java程序在执行过程中先要将源代码编译成字节码文件，然后再由解释器对字节码文件逐句进行解释，所以说Java是一种先编译后解释的语言。（注：Java为了实现跨平台的特性，专门在从高级语言代码转换至机器码过程的中间加入了一层中间层JVM（java虚拟机），Java首先依赖编译器将代码（.java）编译成JVM能识别的字节码文件（.class），然后由JVM解释并执行该字节码，也可结合JIT（just-in-time compilation即时编译）技术，将解释生成的机器码转换为更高效的本地机器码，且该机器码可被缓存，来提高重复执行的效率。)</p><p>&emsp;&emsp;常见的编译型语言包括：C/C++、Pascal等，常见的编译型语言包括：Java、JavaScript、VBScript、Perl、Ruby、MATLAB 等。</p><h4 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h4><ul><li>编译型语言可以做到一次编译，多次运行，执行效率比较高；而解释型语言在每次执行时都需要解释器进行解释，执行效率较低（但是我们也不能一概而论，一些解释型语言也可以通过解释器的优化来在对程序做出翻译时对整个程序做出优化，从而在效率上超过编译型语言）。</li><li>编译型语言的执行依赖于平台，生成的可执行文件不能运行在其他平台，需重新编译，跨平台的性较差；而解释型语言的执行依赖于解释器，各个平台都有相应的解释器，解释器会将程序解释成基于当前机器指令集的机器码并执行，所以解释型语言可以很好的移植到其他平台，具有很好的跨平台性。</li><li>编译型语言，在编译阶段即可发现常见的语法或者链接等错误，此机制可在运行前帮助程序员排查出可能潜在的语法、语义和类型转换错误，编译型语言一般都有明确的变量类型检测，也被称作<strong>强类型语言</strong>，即编译型语言至少能确保所生成的可执行文件肯定是可运行的，至于执行的逻辑不对则属于程序员业务逻辑错误范畴了。而对于解释型语言，代码中的错误必须直到运行阶段方可发现，由此造成的困惑是：往往一段程序看不出问题但却在运行阶段错误连连且需要一个个排查：变量拼写错误、方法不存在等。但也正是基于解释是在运行期执行转化的特性，一般的解释型语言通常都有自己的shell，可以在不确定某些执行结果时立即“动手执行”试一下，这就比每次都需要编译后才能运行并看到结果省去不少时间。</li></ul><h3 id="python"><a href="#python" class="headerlink" title="python"></a>python</h3><p>&emsp;&emsp;通过上面对编译型语言和解释型语言的分析，我们可以得出结论，python是属于解释型语言的一种。python类似于Java，为了效率上的考虑，也提供了编译方式，编译后生成的也是字节码的文件形式，并由Python的的VM（虚拟机）的去执行。不同点在于，Python的编译并非强制执行的操作，确切来说Python的编译是自动的，通常发生在对某个模块（module）的调用过程中，编译成字节码的可以节省加载模块的时间，以此达到提高效率的目的。可见，某些先进的高级语言在对编译和解释方面的拿捏舍去，都采取了一种：两手抓，两手都要硬的态度。</p><h4 id="python解释器"><a href="#python解释器" class="headerlink" title="python解释器"></a>python解释器</h4><p>&emsp;&emsp;由于整个Python语言从规范到解释器都是开源的，所以理论上，只要水平够高，任何人都可以编写Python解释器来执行Python代码（当然难度很大）。事实上，确实存在多种Python解释器</p><ul><li>CPython:  这个解释器是用C语言开发的，所以叫CPython。在命令行下运行python就是启动CPython解释器,它是使用最广的Python解释器.</li><li>IPython是基于CPython之上的一个交互式解释器，也就是说，IPython只是在交互方式上有所增强，但是执行Python代码的功能和CPython是完全一样的。CPython用<code>&gt;&gt;&gt;</code>作为提示符，而IPython用<code>In [序号]:</code>作为提示符。</li><li>绝大部分Python代码都可以在PyPy下运行，但是PyPy和CPython有一些是不同的，这就导致相同的Python代码在两种解释器下执行可能会有不同的结果。PyPy是另一个Python解释器，它的目标是执行速度。PyPy采用<a href="http://en.wikipedia.org/wiki/Just-in-time_compilation" target="_blank" rel="noopener">JIT技术</a>，对Python代码进行动态编译（注意不是解释），所以可以显著提高Python代码的执行速度。</li><li>Jython是运行在Java平台上的Python解释器，可以直接把Python代码编译成Java字节码执行。</li></ul><h4 id="python代码执行过程"><a href="#python代码执行过程" class="headerlink" title="python代码执行过程"></a>python代码执行过程</h4><p>&emsp;&emsp;参考这篇<a href="#https://blog.csdn.net/helloxiaozhe/article/details/78104975">博客</a>和这篇<a href="#https://www.cnblogs.com/kym/archive/2012/05/14/2498728.html">博客</a></p>]]></content:encoded>
      
      <comments>https://chaoge123456.github.io/%E8%A7%A3%E9%87%8A%E5%9E%8B%E8%AF%AD%E8%A8%80python.html/#disqus_thread</comments>
    </item>
    
    <item>
      <title>决策树算法详解与python实现：ID3和CART</title>
      <link>https://chaoge123456.github.io/%E5%86%B3%E7%AD%96%E6%A0%91.html/</link>
      <guid>https://chaoge123456.github.io/%E5%86%B3%E7%AD%96%E6%A0%91.html/</guid>
      <pubDate>Sun, 09 Sep 2018 07:12:47 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt; 决策树是一种基本的分类与回归方法，本文主要讨论用于分类的决策树，决策树模型呈树形结构，在分类问题中，表示基于特征对实例进行分类的过程，它可以认为是if-then规则的集合，也可以认为是定义在特征空间与类空间上的条件概率分布，其主要优点
        
      
      </description>
      
      <content:encoded><![CDATA[<p><strong>摘要</strong> 决策树是一种基本的分类与回归方法，本文主要讨论用于分类的决策树，决策树模型呈树形结构，在分类问题中，表示基于特征对实例进行分类的过程，它可以认为是if-then规则的集合，也可以认为是定义在特征空间与类空间上的条件概率分布，其主要优点是模型具有可读性，分类速度快。学习时，利用训练数据，根据损失函数最小化原则建立决策树模型。预测时，对新的数据，利用决策树模型进行分类。决策树学习通常包括三个步骤：特征选择、决策树的生成以及决策树的修剪。本文将主要讲解ID3和CART算法的原理和实现细节。  </p><img src="http://pcvm1j2f3.bkt.clouddn.com/static/images/verify/tree.png?imageView2/2/w/600">  <h2 id="文章概览"><a href="#文章概览" class="headerlink" title="文章概览"></a>文章概览</h2><ul><li>ID3算法<ul><li>特征选择</li><li>决策树的生成</li><li>ID3算法的缺陷</li><li>C4.5算法对ID3算法的改进</li></ul></li><li>CART算法<ul><li>特征选择</li><li>决策树生成</li><li>剪枝</li></ul></li></ul><h3 id="ID3算法"><a href="#ID3算法" class="headerlink" title="ID3算法"></a>ID3算法</h3><p>&emsp;&emsp;ID3算法是由澳大利亚计算机科学家Ross Quinlan提出的，它是构建决策树中一种非常重要的算法。在设计算法的过程中，它首次采用了信息增益准则来进行特征选择，这很大程度上推动了决策树算法的发展。</p><h4 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h4><p>&emsp;&emsp;我们可以将决策树看作是if- then规则的集合，使用决策树模型进行预测的过程就相当于对if - then规则进行判断，那我们可以想到如果if -then规则越多，也就是决策树越复杂，那么预测所需要的时间越长，所以为了不断优化决策树的决策过程，我们需要合理的构建决策树，那么如何来选择if - then的决策规则至关重要。</p><p>&emsp;&emsp;在ID3算法中，我们通过信息增益作为决策规则。信息增益 = 信息熵 - 条件熵，信息熵代表随机变量的不确定度，条件熵代表在一定条件下，随机变量的复杂度，所以信息增益表示在一定条件下信息复杂度减少的程度。信息增益越大说明该决策规则的区分度越高，在构建决策树时，我们选取信息增益最大的特征作为决策规则。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">emp_entropy</span><span class="params">(y_data)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    emp_entropy函数的主要功能是计算数据集的经验熵</span></span><br><span class="line"><span class="string">    :param y_data: 数据集的类别</span></span><br><span class="line"><span class="string">    :return: 返回数据集的经验熵</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    count = &#123;&#125;</span><br><span class="line">    emp = <span class="number">0.0</span></span><br><span class="line">    m = len(y_data)</span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> y_data:</span><br><span class="line">        <span class="keyword">if</span> y <span class="keyword">in</span> count:</span><br><span class="line">            count[y] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            count[y] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> count.keys():</span><br><span class="line">        info = (<span class="number">1.0</span> * count[i] / m)</span><br><span class="line">        emp = emp + info * math.log(info,<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> emp</span><br></pre></td></tr></table></figure><p>emp_entropy函数的主要功能是计算数据集合的经验熵，经验熵的计算公式可以参考《统计学习方法》，同样，下面涉及到条件熵、信息增益的计算公式也可参考本书。代码中字典count的主要作用是统计数据集中不同类别出现的次数，emp即是信息增益。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">emp_cond_entropy</span><span class="params">(x_data,y_data,feature)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    emp_cond_entropy函数的主要作用是计算经验条件熵</span></span><br><span class="line"><span class="string">    :param x_data: 数据集</span></span><br><span class="line"><span class="string">    :param y_data: 数据集类别</span></span><br><span class="line"><span class="string">    :param feature: 数据集特征特征</span></span><br><span class="line"><span class="string">    :return: 数据集的经验条件熵</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    count_y = &#123;&#125;</span><br><span class="line">    emp_cond = <span class="number">0.0</span></span><br><span class="line">    m = len(y_data)</span><br><span class="line">    fea = x_data[:,feature]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(fea)):</span><br><span class="line">        <span class="keyword">if</span> fea[i] <span class="keyword">in</span> count_y:</span><br><span class="line">            count_y[fea[i]].append(y_data[i])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            count_y.setdefault(fea[i])</span><br><span class="line">            count_y[fea[i]] = []</span><br><span class="line">            count_y[fea[i]].append(y_data[i])</span><br><span class="line">    <span class="keyword">for</span> e <span class="keyword">in</span> count_y.keys():</span><br><span class="line">        l = len(count_y[e])</span><br><span class="line">        emp_cond = emp_cond + (<span class="number">1.0</span> * l / m) * emp_entropy(count_y[e])</span><br><span class="line">    <span class="keyword">return</span> emp_cond</span><br></pre></td></tr></table></figure><p>emp_cond_entropy函数的主要作用是计算经验条件熵，fenture表示数据的某一维特征，对于离散性特征（ID3算法不能处理连续型特征）来讲，特征的取值有多个，这里的count_y就是来统计该特征中不同取值的数据分布情况，列表fea表示的即是该数据集中该特征对应的值，emp_cond表示的是将该特征作为决策规则时的条件熵。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">choose_feature</span><span class="params">(x_data,y_data)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    choose_feature函数的主要作用是从数据集中选择信息增益最大的特征</span></span><br><span class="line"><span class="string">    :param x_data: 数据集</span></span><br><span class="line"><span class="string">    :param y_data: 数据集类别</span></span><br><span class="line"><span class="string">    :return: 信息增益最大的特征</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    n = np.size(x_data,<span class="number">1</span>)</span><br><span class="line">    count = []</span><br><span class="line">    emp = emp_entropy(y_data)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        emp_cond = emp_cond_entropy(x_data,y_data,i)</span><br><span class="line">        count.append(emp - emp_cond)</span><br><span class="line">    feature = count.index(min(count))</span><br><span class="line">    <span class="keyword">return</span> feature</span><br></pre></td></tr></table></figure><p>choose_feature函数的主要作用是从数据集中选择信息增益最大的特征，算法的思路就是对数据集进行遍历，计算每一个特征的信息增益，返回信息增益最大的特征。（由于在计算经验熵的过程中没有添加负号，所以我这里取的是负数的最小值，也就是正数的最大值）</p><h4 id="决策树的生成"><a href="#决策树的生成" class="headerlink" title="决策树的生成"></a>决策树的生成</h4><p>&emsp;&emsp;特征树的生成过程其实是一个递归过程，我们首先选择一个特征，作为根结点，根据根结点的不同取值，将数据集分为几个不同的部分，同时将该特征从数据集中删除。然后再对这几个不同的部分进行同样的操作，直到数据集类别相同或者没有特征为止。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_tree</span><span class="params">(x_data,y_data,feature_list_data)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    create_tree函数的主要作用是构建决策树</span></span><br><span class="line"><span class="string">    :param x_data:</span></span><br><span class="line"><span class="string">    :param y_data:</span></span><br><span class="line"><span class="string">    :param feature_list:</span></span><br><span class="line"><span class="string">    :return: 返回决策树</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    feature_list = feature_list_data[:]</span><br><span class="line">    <span class="keyword">if</span> is_all_same(y_data):</span><br><span class="line">        <span class="keyword">return</span> y_data[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> len(x_data) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> node_classfy(y_data)</span><br><span class="line">    feature = choose_feature(x_data,y_data)</span><br><span class="line">    node_name = feature_list[feature]</span><br><span class="line">    tree = &#123;node_name:&#123;&#125;&#125;</span><br><span class="line">    <span class="keyword">del</span> feature_list[feature]</span><br><span class="line">    count_x,count_y = feature_split(x_data,y_data,feature)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> count_x.keys():</span><br><span class="line">        fealist = feature_list[:]</span><br><span class="line">        count_x_del = del_feature(count_x[i],feature)</span><br><span class="line">        tree[node_name][i] = create_tree(count_x_del,count_y[i],fealist)</span><br><span class="line">    <span class="keyword">return</span> tree</span><br></pre></td></tr></table></figure><p>feature_list的作用是复制feature_list_data，因为后面要进行删除操作，我们要保证删除操作只能影响函数内部变量，不能对函数的实参造成影响。我们生成的决策树保存在tree字典中，每执行一次递归操作，相当于将当前特征作为一个字典的key，递归操作返回的即是一个子树（即字典）。</p><h4 id="ID3算法的缺陷"><a href="#ID3算法的缺陷" class="headerlink" title="ID3算法的缺陷"></a>ID3算法的缺陷</h4><p>&emsp;&emsp;通过对ID3算法进行分析，我们可以知道，ID3算法主要存在以下缺陷：</p><ul><li>ID3没有考虑连续型特征，数据集的特征必须是离散型特征</li><li>ID3算法采用信息增益大的特征优先建立决策树的结点，但是再计算信息增益的过程中我们发现，在相同条件下，取值比较多的特征比取值少的特征信息增益大</li><li>ID3没有对缺失值情况进行处理，现实任务中常会遇到不完整的样本，即样本的某些属性值缺失。</li><li>没有考虑过拟合问题</li></ul><h4 id="C4-5算法对ID3算法的改进"><a href="#C4-5算法对ID3算法的改进" class="headerlink" title="C4.5算法对ID3算法的改进"></a>C4.5算法对ID3算法的改进</h4><p>&emsp;&emsp;C4.5算法是对ID3算法存在的缺陷进行改进的一种算法，它通过将连续特征离散化来解决ID3算法不能处理离散型数据的问题（这个会在后面的CART算法中讲到）；通过引入信息增益比来解决信息增益的缺陷；通过增加剪枝操作来解决过拟合的问题。</p><h3 id="CART算法"><a href="#CART算法" class="headerlink" title="CART算法"></a>CART算法</h3><p>&emsp;&emsp;CART算法是一种应用广泛的决策树算法，它的基本流程与C4.5算法类似，它既可以应用于回归任务，也可以应用于分类任务（这里主要讲解分类树），需要注意的是CART算法生成的决策树是二叉树，而ID3和C4.5算法生成的决策树不一定是二叉树。</p><h4 id="特征选择-1"><a href="#特征选择-1" class="headerlink" title="特征选择"></a>特征选择</h4><p>&emsp;&emsp;CART算法的决策规则由基尼指数决定，选择基尼指数最小的特征及其切分点作为最优特征和最优切分点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Gini_index</span><span class="params">(y_data)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Gini_index函数的主要作用是计算数据集的基尼指数</span></span><br><span class="line"><span class="string">    :param y_data: 数据集类别</span></span><br><span class="line"><span class="string">    :return: 返回基尼指数</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    m = len(y_data)</span><br><span class="line">    count = &#123;&#125;</span><br><span class="line">    num = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> y_data:</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> count:</span><br><span class="line">            count[i] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            count[i] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> count.keys():</span><br><span class="line">        num = num + pow(<span class="number">1.0</span> * count[item] / m,<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> (<span class="number">1.0</span>-num)</span><br></pre></td></tr></table></figure><p>在前面提到过ID3算法只能处理离散型特征，而CART算法既能处理离散型特征，又能处理连续型特征。CART算法处理连续型特征的方法与C4.5算法类似，都是将连续特征离散化，即将连续特征的所有取值进行排序，然后计算相邻取值的平均值作为切分点，在以此计算基尼指数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">ef Gini_D_A(x_data,y_data,feature):</span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Gini_D_A函数的主要作用是计算某一离散特征各个取值的基尼指数，选取最优切分点</span></span><br><span class="line"><span class="string">    :param x_data: 数据集合</span></span><br><span class="line"><span class="string">    :param y_data: 数据集类别</span></span><br><span class="line"><span class="string">    :param feature: 特征</span></span><br><span class="line"><span class="string">    :return: 该特征的最优切分点</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    Gini_data = list(x_data[:,feature])</span><br><span class="line">    y_data = list(y_data[:])</span><br><span class="line">    m = len(Gini_data)</span><br><span class="line">    Gini = &#123;&#125;</span><br><span class="line">    classfy_data = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> e <span class="keyword">in</span> range(m):</span><br><span class="line">        <span class="keyword">if</span> Gini_data[e] <span class="keyword">not</span> <span class="keyword">in</span> classfy_data:</span><br><span class="line">            classfy_data[Gini_data[e]] = []</span><br><span class="line">        classfy_data[Gini_data[e]].append(y_data[e])</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> classfy_data.keys():</span><br><span class="line">        l1 = len(classfy_data[item])</span><br><span class="line">        r = y_data[:]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> classfy_data[item]:</span><br><span class="line">            r.remove(i)</span><br><span class="line">        l2 = len(r)</span><br><span class="line">        num = <span class="number">1.0</span> * l1 / m * Gini_index(classfy_data[item]) + <span class="number">1.0</span> * l2 / m * Gini_index(r)</span><br><span class="line">        Gini[item] = num</span><br><span class="line">    sor = sorted(Gini.items(), key=operator.itemgetter(<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> sor[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Gini_continuous</span><span class="params">(x_data,y_data,feature)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Gini_continous函数的主要作用是计算某一连续特征各个取值的基尼指数，选取最优切分点</span></span><br><span class="line"><span class="string">    :param x_data: 数据集合</span></span><br><span class="line"><span class="string">    :param y_data: 数据集类别</span></span><br><span class="line"><span class="string">    :param feature: 特征</span></span><br><span class="line"><span class="string">    :return: 该特征的最优切分点</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    Gini_data = list(x_data[:,feature])</span><br><span class="line">    m = len(Gini_data)</span><br><span class="line">    y_data = list(y_data[:])</span><br><span class="line">    sort_data = sorted(Gini_data)</span><br><span class="line">    Gini = &#123;&#125;</span><br><span class="line">    split_point = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m<span class="number">-1</span>):</span><br><span class="line">        num = (sort_data[i] + sort_data[i+<span class="number">1</span>]) / <span class="number">2.0</span></span><br><span class="line">        split_point.append(num)</span><br><span class="line">    <span class="keyword">for</span> e <span class="keyword">in</span> split_point:</span><br><span class="line">        count_y = &#123;<span class="number">0</span>:[],<span class="number">1</span>:[]&#125;</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(m):</span><br><span class="line">            <span class="keyword">if</span> Gini_data[k] &lt;= e:</span><br><span class="line">                count_y[<span class="number">0</span>].append(y_data[k])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                count_y[<span class="number">1</span>].append(y_data[k])</span><br><span class="line">        cal = <span class="number">1.0</span> * len(count_y[<span class="number">0</span>]) / m * Gini_index(count_y[<span class="number">0</span>]) + <span class="number">1.0</span> * len(count_y[<span class="number">1</span>]) / m * Gini_index(count_y[<span class="number">1</span>])</span><br><span class="line">        Gini[e] = cal</span><br><span class="line">    sor = sorted(Gini.items(), key=operator.itemgetter(<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> sor[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>当数据集中同时含有离散型变量和连续型变量时，进行特征选择就稍微有些复杂了，以下便是特征选择的代码,这里需要注意的是对不同类型特征的标识和对计算基尼指数时返回值的统一处理。dis_or_con是一个列表，用来标识特征是连续型还是离散型，0表示离散，1表示连续。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">choose_feature</span><span class="params">(x_data,y_data,dis_or_con)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    choose_feature函数的主要作用是从各个特征的各个切分点中选择基尼指数最小的切分点</span></span><br><span class="line"><span class="string">    :param x_data: 数据集合</span></span><br><span class="line"><span class="string">    :param y_data: 数据类别</span></span><br><span class="line"><span class="string">    :return: 切分点</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    w = np.size(x_data,axis=<span class="number">1</span>)</span><br><span class="line">    count = []</span><br><span class="line">    count_label = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(w):</span><br><span class="line">        <span class="keyword">if</span> dis_or_con[i] == <span class="number">0</span>:</span><br><span class="line">            a = Gini_D_A(x_data,y_data,i)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            a = Gini_continuous(x_data,y_data,i)</span><br><span class="line">        count.append(a[<span class="number">1</span>])</span><br><span class="line">        count_label[i] = a</span><br><span class="line">    id = count.index(min(count))</span><br><span class="line">    <span class="keyword">return</span> id,count_label[id][<span class="number">0</span>]</span><br></pre></td></tr></table></figure><h4 id="决策树的生成-1"><a href="#决策树的生成-1" class="headerlink" title="决策树的生成"></a>决策树的生成</h4><p>&emsp;&emsp;决策树的生成大致与ID3算法类似</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_tree</span><span class="params">(x_data,y_data,dis_or_con_data,feature_list_data)</span>:</span></span><br><span class="line"></span><br><span class="line">    feature_list = feature_list_data[:]</span><br><span class="line">    dis_or_con = dis_or_con_data[:]</span><br><span class="line">    <span class="keyword">if</span> dis_or_con == []:</span><br><span class="line">        <span class="keyword">return</span> most_y_data(y_data)</span><br><span class="line">    <span class="keyword">if</span> is_all_same(y_data):</span><br><span class="line">        <span class="keyword">return</span> y_data[<span class="number">0</span>]</span><br><span class="line">    w,f = choose_feature(x_data,y_data,dis_or_con)</span><br><span class="line">    count_x, count_y = feature_split(x_data,y_data,w,f,dis_or_con[w])</span><br><span class="line">    node_name = feature_list[w]</span><br><span class="line">    tree = &#123;(node_name,f):&#123;&#125;&#125;</span><br><span class="line">    <span class="keyword">del</span> feature_list[w]</span><br><span class="line">    <span class="keyword">del</span> dis_or_con[w]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> count_x.keys():</span><br><span class="line">        fealist = feature_list[:]</span><br><span class="line">        dis_con = dis_or_con[:]</span><br><span class="line">        count_x_del = del_feature(count_x[i], w)</span><br><span class="line">        tree[(node_name,f)][i] = create_tree(count_x_del, count_y[i], dis_con,fealist)</span><br><span class="line">    <span class="keyword">return</span> tree</span><br></pre></td></tr></table></figure><h4 id="剪枝"><a href="#剪枝" class="headerlink" title="剪枝"></a>剪枝</h4><p>&emsp;&emsp;本文暂未实现剪枝算法，有待后续补充</p>]]></content:encoded>
      
      <comments>https://chaoge123456.github.io/%E5%86%B3%E7%AD%96%E6%A0%91.html/#disqus_thread</comments>
    </item>
    
    <item>
      <title>验证码识别：找回四六级准考证号</title>
      <link>https://chaoge123456.github.io/verify-code.html/</link>
      <guid>https://chaoge123456.github.io/verify-code.html/</guid>
      <pubDate>Wed, 29 Aug 2018 12:27:33 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt; 一晃时间过的真快，距离上次更新博客已经将近10天了，这十天来也没闲着，回家终于把杀千刀的科目三过了，再也不用看到教练那张凶神恶煞的脸。前段时间四六级考试成绩公布了，小伙伴们是不是都第一时间忙着去查自己的成绩，相信有很多小伙伴跟我一样苦
        
      
      </description>
      
      <content:encoded><![CDATA[<p><strong>摘要</strong> 一晃时间过的真快，距离上次更新博客已经将近10天了，这十天来也没闲着，回家终于把杀千刀的科目三过了，再也不用看到教练那张凶神恶煞的脸。前段时间四六级考试成绩公布了，小伙伴们是不是都第一时间忙着去查自己的成绩，相信有很多小伙伴跟我一样苦逼，幸幸苦苦复习了好长时间，查成绩的时候却忘了自己的准考证号（温馨提示：以后考试之前一定要记得把准考证拍一张存起来）。在网上试过无数种找回办法后，我彻底绝望了。既然别人不靠谱，咱就靠自己，经过两天的努力之后，终于成功的找回了准考证号。这篇博客主要来介绍解决这个问题的一些方法和思路。</p><img class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/verify/python.png?imageView2/2/w/600">    <h1 id="文章概览"><a href="#文章概览" class="headerlink" title="文章概览"></a>文章概览</h1><ul><li><a href="#idea">基本思路</a>  </li><li><a href="#train">训练模型</a>  <ul><li>获取训练数据</li><li>处理数据</li><li>生成模型  </li></ul></li><li><a href="#select">查询操作</a>  <ul><li>发送请求</li><li>使用代理</li><li>多线程  </li></ul></li><li><a href="#instruction">使用教程</a></li></ul><p></p><h2 id="idea">基本思路</h2><br>&emsp;&emsp;对于查询四六级成绩来说，官方的查询入口有<a href="https://www.chsi.com.cn/cet/" target="_blank" rel="noopener">学信网</a>和<a href="http://cet.neea.edu.cn/cet/" target="_blank" rel="noopener">中国教育考试网</a>，查询成绩需要提交的数据包括准考证号、姓名和验证码。要想查询到成绩，最简单的办法就是手工枚举准考证号，一个一个的尝试。我们知道四六级准考证的组成如下所示（第10位表示类别，四级是1，六级是2）：<br><img class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/verify/constitute.png?imageView2/2/w/600"><br>也就是说对于在同在一个考点的人来说前十位都是一致的（四级和六级不同），后面五位分别表示考场号和座位号（座位号从01到30），在我们忘记了考场号和座位号的情况下，我们至少要手工枚举几千次才有可能查询到成绩，这个工作难度可想而知。那如果我们不采用手工的方式进行枚举，而采用程序自动进行枚举呢？通过程序枚举准考证号不是什么问题，但是查询参数中包含验证码，现在需要解决地就是如何识别验证码。对于验证码地识别问题，我们可以利用机器学习的相关算法，建立识别模型，再利用识别模型来进行识别验证码。对于学信网和中国教育考试网两个网站，它们采用的验证码不同，学信网的验证码比较复杂，包含汉字等特殊字符，识别难度大，而中国教育考试网的验证码相对来说比较常规，识别难度相对小一点，本文的查询操作都是基于后者而言的。<br>&emsp;&emsp;那么我们解决问题地大致思路就是：首先我们要获取大量的验证码数据，然后选择算法训练识别验证码的模型，最后通过重复识别查询页面的验证码，提交查询数据，分析响应数据来获得最终的结果。  <p></p><p></p><h2 id="train">训练模型</h2><p></p><h3 id="获取训练数据"><a href="#获取训练数据" class="headerlink" title="获取训练数据"></a>获取训练数据</h3><p>&emsp;&emsp;通过抓取请求相应过程中的数据包，我们可以得到获取验证码的地址。</p><img class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/verify/imgurl.PNG?imageView2/2/w/600">   <p>其中ik表示准考证号，我们可以随便填一个，t表示时间戳（这个可以不用管），我们可以不断地向这个地址发送请求，服务器的响应结果即为验证码的地址，我们再向获取到的验证码的地址发送请求，就可以得到验证码。</p><img class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/verify/imgresp.PNG?imageView2/2/w/600">    <p>具体代码如下所示（该项目的所有代码都可以在<a href="https://github.com/chaoge123456/" target="_blank" rel="noopener">我的Github</a>中找到）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取验证码</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_image_to_file</span><span class="params">()</span>:</span></span><br><span class="line">    myid = <span class="string">"123456789110211"</span></span><br><span class="line">    new_id = myid.format(id=myid)</span><br><span class="line">    img_api_url = image_api.format(id=new_id)</span><br><span class="line">    img_api_resp = requests.get(img_api_url, headers=img_api_headers,timeout=<span class="number">10</span>)</span><br><span class="line">    img_url, filename = get_image_url_and_filename(img_api_resp.text)</span><br><span class="line">    r = requests.get(img_url)</span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">"images/raw_picture/"</span> + filename, <span class="string">"wb+"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(r.content)</span><br></pre></td></tr></table></figure><h3 id="处理数据"><a href="#处理数据" class="headerlink" title="处理数据"></a>处理数据</h3><p>&emsp;&emsp;获取到一定数量的验证码图片后（大概需要100多张，收集的图片越多越好，之后我们会讲到一种快速收集和标注验证码的方法），接下来我们需要对获取到的验证码进行相应的处理。因为对于验证码的识别，我们一般采取监督学习的算法训练模型，所以首先要对获取到的验证码进行标注，即将验证码图片的文件名改为验证码对应的数字和字母组合，这一步必须要人工进行操作。然后，为了提高验证码识别的准确率，训练更好的识别模型，我们需要对验证码图片进行相应的处理，如灰度处理、二值化、降噪。经过这些手段处理后的验证码更能体现出图片本身的特征，同时也减小了训练模型时的计算量，具体代码如下所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 灰度处理，二值化（降噪部分的代码去掉了，效果不是太理想）</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">img_denoise</span><span class="params">(img, threshold)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_table</span><span class="params">(threshold=threshold)</span>:</span></span><br><span class="line">        table = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">256</span>):</span><br><span class="line">            <span class="keyword">if</span> i &lt; threshold:</span><br><span class="line">                table.append(<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                table.append(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> table</span><br><span class="line"></span><br><span class="line">    img = img.convert(<span class="string">"L"</span>).point(init_table(), <span class="string">'1'</span>)</span><br><span class="line">    <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;下面我们要对验证码进行分割，因为在识别的时候，我们是识别单个的数字或字母，所以我们要将验证码进行切分，提取出每个字符对应的区域，切割后的每张图片大小一致。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 图片分割,参数img_split_start指定起始位置，参数img_split_width指定切割图片宽度</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">img_split</span><span class="params">(img,img_split_start,img_split_width)</span>:</span></span><br><span class="line">    start = img_split_start</span><br><span class="line">    width = img_split_width</span><br><span class="line">    top = <span class="number">0</span></span><br><span class="line">    height = img.size[<span class="number">1</span>]</span><br><span class="line">    img_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">        new_start = start + width * i</span><br><span class="line">        box = (new_start, top, new_start + width, height)</span><br><span class="line">        piece = img.crop(box)</span><br><span class="line">        <span class="comment">#piece.save("%s.jpg" % i)</span></span><br><span class="line">        img_list.append(piece)</span><br><span class="line">    <span class="keyword">return</span> img_list</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;图片切割完成后，数据处理的最后一步是将切割后的图片转化为numpy array的形式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将Image对象转换为array_list</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">img_list_to_array_list</span><span class="params">(img_list)</span>:</span></span><br><span class="line">    array_list = []</span><br><span class="line">    <span class="keyword">for</span> img <span class="keyword">in</span> img_list:</span><br><span class="line">        array_list.append(array(img).flatten())</span><br><span class="line">    <span class="keyword">return</span> array_list</span><br></pre></td></tr></table></figure><p>以上这些操作大家可以在我的GitHub的项目文件中通过preprocessing()、make_train_data()和img_to_array()三个函数实现。</p><h3 id="生成模型"><a href="#生成模型" class="headerlink" title="生成模型"></a>生成模型</h3><p>&emsp;&emsp;生成模型主要用到的就是sklearn机器学习库中相关的算法，验证码识别属于分类任务，对于分类任务我们可以采用K近邻、支持向量机、决策树和神经网络等算法，这里我们采用的是支持向量机。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">svm_model</span><span class="params">(x_data,y_data)</span>:</span></span><br><span class="line">    SVM = svm.SVC()</span><br><span class="line">    x_train,x_test,y_train,y_test = train_test_split(x_data,y_data,random_state=<span class="number">14</span>)</span><br><span class="line">    SVM.fit(x_train,y_train)</span><br><span class="line">    y_predict = SVM.predict(x_test)</span><br><span class="line">    average_accuracy = np.mean(y_test==y_predict)*<span class="number">100</span></span><br><span class="line">    print(<span class="string">"准确率为：&#123;0:.1f&#125;%"</span>.format(average_accuracy))</span><br><span class="line">    pickle.dump(SVM, open(<span class="string">"model.pkl"</span>, <span class="string">"wb+"</span>))</span><br></pre></td></tr></table></figure><p>模型训练好之后，将模型对象存储在model.pkl文件中，需要识别验证码时，只需要读取model.pkl文件即可获得识别模型，不需要再次训练。</p><h2 id="查询操作"><a href="#查询操作" class="headerlink" title="查询操作"></a>查询操作</h2><h3 id="发送请求"><a href="#发送请求" class="headerlink" title="发送请求"></a>发送请求</h3><p>&emsp;&emsp;模型训练好之后，我们就可以进行查询操作了。这一阶段的大致思路是，先获取查询页面的验证码，通过识别模型进行识别，然后再向服务器提交请求参数，包括枚举的准考证号、姓名和验证码。如果服务器返回验证码错误，则重复以上操作。如果服务器返回查询结果为空则说明验证码正确，但是准考证号和姓名不一致，此时可以枚举下一个准考证号，重复操作一直到获得正确结果为止。</p><p>&emsp;&emsp;由于一开始我们训练模型时使用的训练数据量很小，所以该识别模型识别的准确率比较低，那么如何提高模型识别的准确率呢。最好的办法就是增大训练数据的数量，训练新的模型。这里提供一个更快更方便获取训练数据的方法，在发送请求的代码中，我们加入两行代码（倒数第三行和倒数第二行），该代码的作用时将识别正确的验证码加入到训练数据的文件夹中，并且会自动进行标注，可以通过该方式一边查询，一边收集大量的训练数据。我的项目中，一开始手工标注的验证码有200张，训练模型后采用这种方式自动收集了1600多张验证码，然后利用所有的训练数据重新建立模型，识别的准确率提高了30%。（但是这样的做法存在一个过拟合的问腿，训练模型对于类似于一开始200张验证码的图片的识别准确率比较高，而对于其他类型的图片识别的准确率比较低。不过这个问题对于我们找回准考证号影响不大，提高准确率最好的就是一开始手工标注更多的验证码）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 发送请求</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">send_query_until_true</span><span class="params">(num)</span>:</span></span><br><span class="line">    <span class="comment"># 生成准考证号</span></span><br><span class="line">    <span class="keyword">global</span> proxy</span><br><span class="line">    new_id = myid.format(id=num)</span><br><span class="line">    <span class="comment"># 获取验证码图片地址</span></span><br><span class="line">    img_api_url = image_api.format(id=new_id)</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            img_api_resp = requests.get(img_api_url,        headers=img_api_headers,timeout=<span class="number">10</span>,proxies=proxy)</span><br><span class="line">            img_url, filename = get_image_url_and_filename(img_api_resp.text)</span><br><span class="line">            <span class="comment"># 获取验证码图片并猜测</span></span><br><span class="line">            img_resp = requests.get(img_url, timeout=<span class="number">10</span>, proxies=proxy)</span><br><span class="line">            <span class="keyword">if</span> img_resp.status_code == <span class="number">200</span>:</span><br><span class="line">                images = Image.open(BytesIO(img_resp.content))</span><br><span class="line">                code = img_verify_code(images)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                code = <span class="string">"xxxx"</span></span><br><span class="line">        <span class="keyword">except</span> Exception:</span><br><span class="line">            print(<span class="string">"重新获取代理"</span>)</span><br><span class="line">            p = str(get_proxy())</span><br><span class="line">            proxy = &#123;<span class="string">'http'</span>: <span class="string">'http://'</span> + p, <span class="string">'https'</span>: <span class="string">'http://'</span> + p&#125;</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="comment"># CET4成绩查询选项</span></span><br><span class="line">    <span class="comment"># data = &#123;"data": "CET4_181_DANGCI,&#123;id&#125;,&#123;name&#125;".format(id=new_id, name=name),"v": code&#125;</span></span><br><span class="line">    <span class="comment"># CET6成绩查询选项</span></span><br><span class="line">    data = &#123;<span class="string">"data"</span>: <span class="string">"CET6_181_DANGCI,&#123;id&#125;,&#123;name&#125;"</span>.format(id=new_id, name=name),<span class="string">"v"</span>: code&#125;</span><br><span class="line">    query_resp = requests.post(query_api, data=data, headers=query_api_headers)</span><br><span class="line">    query_text = query_resp.text</span><br><span class="line">    log_info(query_text.split(<span class="string">"'"</span>)[<span class="number">3</span>],new_id)</span><br><span class="line">    <span class="keyword">if</span> <span class="string">"验证码错误"</span> <span class="keyword">in</span> query_text:</span><br><span class="line">        query_text = send_query_until_true(num)</span><br><span class="line">    <span class="comment"># elif "您查询的结果为空" in query_text:</span></span><br><span class="line">    <span class="comment">#     images.save("images/save_picture/" + code + ".png")</span></span><br><span class="line">    <span class="keyword">return</span> query_text</span><br></pre></td></tr></table></figure><h3 id="使用代理"><a href="#使用代理" class="headerlink" title="使用代理"></a>使用代理</h3><p>&emsp;&emsp;在上面那段代码中，我们在请求过程中使用了代理，是为了防止频繁请求导致ip被封，代理功能可以自动切换代理，保证程序的正常运行。在测试过程中我们发现，该网站不会对ip进行封锁，所以代理可有可无。这里大致说一下代理功能是如何实现的。</p><p>&emsp;&emsp;代理功能使用的代理池是Github上的开源项目，它通过从代理平台抓取可用的代理ip存储到本地Redis中，需要使用代理时，即从本地Redis中取出。使用代理功能需要进行相应的配置。</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">安装并开启<span class="selector-tag">Redis</span>服务器</span><br><span class="line">安装依赖 <span class="selector-tag">pip3</span> <span class="selector-tag">install</span> <span class="selector-tag">-r</span> <span class="selector-tag">requirements</span><span class="selector-class">.txt</span></span><br><span class="line">开启代理服务 <span class="selector-tag">python</span> <span class="selector-tag">run</span><span class="selector-class">.py</span></span><br></pre></td></tr></table></figure><p>&emsp;&emsp;在上述代码中，我们使用了捕捉异常的语句，因为在使用代理的过程中我们发现代理ip可能存在网络不稳定，传输有延时等问题。总的来说，使用代理的查询速度很慢，不想使用代理的话直接将proxy配置成本地的ip和端口即可。</p><h3 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h3><p>&emsp;&emsp;在开发过程中，想过用多线程，但是效果不太理想（对并行编程不熟悉），后来想想对于查找准考证号这种问题可以根据实际情况灵活，可能有些人会大致记得自己的考场位于哪个区间之内，所以在项目中，提供了输入查询区间的接口。如果想提高查询速度，可以开启多个终端，每个终端输入不同的查询区间，这样就类似于开启了多进程（一般查询的时候开启10个终端，每个终端的考场区间为10，10分钟内可以查询到结果）。</p><h2 id="使用教程"><a href="#使用教程" class="headerlink" title="使用教程"></a>使用教程</h2><p>&emsp;&emsp;简单介绍一下该项目的文件结构，如图所示。</p><img class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/verify/content.PNG?imageView2/2/w/600">  <ul><li>images：主要用来存放验证码图片，images中包含多个目录，row_picture存放原始验证码，change_picture存        * 放灰度化、二值化处理后的验证码，train_data存放分割后的验证码</li><li>proxypool：实现代理功能的相关代码</li><li>acquire_picture.py：包含验证码获取、处理相关操作的代码</li><li>model.pkl：存放识别模型</li><li>recongnition_code.py：项目的执行入口，包含向服务器发送请求、代理等相关代码</li><li>setting.py：项目相关的配置文件</li><li>train_data_preprocessing.py：整合验证码获取和处理相关操作</li><li>train_model.py：训练模型</li></ul><p>&emsp;&emsp;该项目使用的大致流程如下（要求python版本不低于3.5，该项目在win10环境测试运行无误）。</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">安装相关依赖PIL、requests、numpyy、sklearn等</span><br><span class="line">修改recongnition_code.<span class="keyword">py</span>文件中的myid（准考证号前<span class="number">10</span>位）、name（自己的名字）</span><br><span class="line">修改recongnition_code.<span class="keyword">py</span>文件中成绩查询选项</span><br><span class="line">如果需要使用代理，需要配置代理相关环境</span><br><span class="line">在项目文件夹中打开终端输入：<span class="keyword">python</span> recongnition_code.<span class="keyword">py</span> 开始区间 结束区间</span><br><span class="line">可同时开启多个终端，每个设置不同的区间，加快查找速度</span><br></pre></td></tr></table></figure><img class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/verify/start.PNG?imageView2/2/w/600">  <img class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/verify/end.PNG?imageView2/2/w/600">]]></content:encoded>
      
      <comments>https://chaoge123456.github.io/verify-code.html/#disqus_thread</comments>
    </item>
    
    <item>
      <title>2018年下半年学习计划</title>
      <link>https://chaoge123456.github.io/plan.html/</link>
      <guid>https://chaoge123456.github.io/plan.html/</guid>
      <pubDate>Wed, 15 Aug 2018 02:25:02 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;&lt;strong&gt;摘要:&lt;/strong&gt; 即将开始研究生阶段的学习生活了，我希望这对于我来说是一个全新的开始。所有伟大的梦想都源于一个切实可行的计划，为了迎接即将开始的旅程，我也需要这样一个计划，希望在它的鞭策和激励下让我不断成长，奋力前行！&lt;br&gt;&lt;img class=&quot;
        
      
      </description>
      
      <content:encoded><![CDATA[<p><strong>摘要:</strong> 即将开始研究生阶段的学习生活了，我希望这对于我来说是一个全新的开始。所有伟大的梦想都源于一个切实可行的计划，为了迎接即将开始的旅程，我也需要这样一个计划，希望在它的鞭策和激励下让我不断成长，奋力前行！<br><img class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/KNN/plan.jpg?imageView2/2/w/600">   </p><h1 id="计划大纲"><a href="#计划大纲" class="headerlink" title="计划大纲"></a>计划大纲</h1><ul><li><a href="#August">2018.8.16-2018.9.1</a>  <ul><li>机器学习算法实现系列博客（贝叶斯分类器和决策树）</li><li>学习python数据结构和算法  </li></ul></li><li><a href="#September">2018.9.2-2018.9.30</a>  <ul><li>阅读高质量论文两篇 </li><li>完成机器学习算法实现系列博客（大概5篇）</li><li>开始阅读《凸优化理论》 </li></ul></li><li><a href="#October">2018.10.1-2018.10.31</a>  <ul><li>阅读高质量论文三篇</li><li>完成《凸优化理论》的学习</li><li>开始阅读流畅的python  </li><li>博客写作三篇  </li></ul></li><li><a href="#November">2018.11.1-2018.11.30</a>  <ul><li>阅读高质量论文三篇</li><li>完成流畅的python</li><li>学习javascript  </li><li>博客写作三篇</li></ul></li><li><a href="#December">2018.12.1-2018.12.31</a>  <ul><li>阅读高质量论文三篇</li><li>学习node.js</li><li>阅读HTTP协议详解  </li><li>博客写作三篇</li></ul></li><li><a href="#January">2018.1.1-2018.1.31</a><ul><li>阅读高质量论文三篇</li><li>搭建node.js网站</li><li>学习docker  </li><li>博客写作三篇</li></ul></li></ul><h2 id="August">八月学习计划完成情况</h2>]]></content:encoded>
      
      <comments>https://chaoge123456.github.io/plan.html/#disqus_thread</comments>
    </item>
    
    <item>
      <title>HTTPS详解：SSL/TLS协议</title>
      <link>https://chaoge123456.github.io/TLS.html/</link>
      <guid>https://chaoge123456.github.io/TLS.html/</guid>
      <pubDate>Mon, 06 Aug 2018 13:14:23 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;&lt;strong&gt;摘要:&lt;/strong&gt; 最近在看关于web安全相关的书籍，说到web安全HTTP和HTTPS之间的联系和区别是一个无法回避的问题。很长时间以来，我也被这个问题所困扰，对于其中涉及的细节问题更是难以触及，但是现在是该去好好考虑这个问题了。在网上查阅了大量资料
        
      
      </description>
      
      <content:encoded><![CDATA[<p><strong>摘要:</strong> 最近在看关于web安全相关的书籍，说到web安全HTTP和HTTPS之间的联系和区别是一个无法回避的问题。很长时间以来，我也被这个问题所困扰，对于其中涉及的细节问题更是难以触及，但是现在是该去好好考虑这个问题了。在网上查阅了大量资料之后，我发现很多文章在解释这个问题的时候含糊不清，让人难以理解。所以我写下了这篇博客，希望能给大家提供帮助，如有不足之处，欢迎指正！<br><img alt="http" class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/TLS/http_vs_https.png?imageView2/2/w/600">  </p><h1 id="文章概览"><a href="#文章概览" class="headerlink" title="文章概览"></a>文章概览</h1><ul><li><a href="#difference">区别与联系</a><ul><li>HTTP和HTTPS<ul><li>联系</li><li>区别</li></ul></li><li>SSL和TLS<ul><li>联系</li><li>区别</li></ul></li></ul></li><li><a href="#protocol">SSL/TLS协议</a><ul><li>密码套件</li><li>记录协议</li><li>握手协议</li><li>前向安全</li></ul></li><li><a href="#openssl">OPENSSL</a></li></ul><h2 id="difference">区别与联系</h2><h3>HTTP和HTTPS</h3><br><h4>联系</h4><br>&emsp;&emsp;HTTP（超文本传输协议）是一个客户端终端（用户）和服务器端（网站）请求和应答的标准（TCP）。通过使用网页浏览器、网络爬虫或者其它的工具，客户端发起一个HTTP请求到服务器上指定端口（默认端口为80）。我们称这个客户端为用户代理程序（user agent）。应答的服务器上存储着一些资源，比如HTML文件和图像。我们称这个应答服务器为源服务器（origin server）。在用户代理和源服务器中间可能存在多个“中间层”，比如代理服务器、网关或者隧道（tunnel）。可以从HTTP头、HTTP请求方法、HTTP状态码和统一资源定位符URL四个方面深入理解HTTP协议。<br><img title="HTTP存在的问题" alt="HTTP存在的问题" class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/TLS/http-problems.png?imageView2/2/w/600"><br>&emsp;&emsp;超文本传输协议HTTP协议被用于在Web浏览器和网站服务器之间传递信息。HTTP协议以明文方式发送内容，不提供任何方式的数据加密，易遭受窃听、篡改、劫持等攻击，因此HTTP协议不适合传输一些敏感信息，比如信用卡号、密码等。为了解决HTTP协议的这一缺陷，需要使用另一种协议：安全套接字层超文本传输协议HTTPS。为了数据传输的安全，HTTPS在HTTP的基础上加入了SSL/TLS协议，SSL/TLS依靠证书来验证服务器的身份，并为浏览器和服务器之间的通信加密，一次HTTPS协议实现了数据传输过程中的保密性、完整性和身份认证性。<br><h4>区别</h4><br>&emsp;&emsp;HTTP和HTTPS的主要区别如下包括:HTTPS协议需要到CA申请证书,而HTTP协议则不用；HTTP是超文本传输协议，信息是明文传输，而HTTPS则是加密传输；HTTP和HTTPS使用完全不同的连接方式，所占用的端口也不一样，前者占用80端口，后者占用443端口；HTTPS传输过程比较复杂，对服务端占用的资源比较多，由于握手过程的复杂性和加密传输的特性导致HTTPS传输的效率比较低；HTTP的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比HTTP协议安全。<br><h3>SSL和TLS</h3><p></p><h4>联系</h4><br>&emsp;&emsp;SSL(Secure Sockets Layer 安全套接层)为Netscape所研发，用以保障在Internet上数据传输之安全，利用数据加密(Encryption)技术，可确保数据在网络上之传输过程中不会被截取及窃听。SSL协议位于TCP/IP协议与各种应用层协议之间，为数据通讯提供安全支持。SSL协议可分为两层： SSL记录协议（SSL Record Protocol）：它建立在可靠的传输协议（如TCP）之上，为高层协议提供数据封装、压缩、加密等基本功能的支持。 SSL握手协议（SSL Handshake Protocol）：它建立在SSL记录协议之上，用于在实际的数据传输开始前，通讯双方进行身份认证、协商加密算法、交换加密密钥等。<br>&emsp;&emsp;安全传输层协议（TLS）用于在两个通信应用程序之间提供保密性和数据完整性。该协议由两层组成： TLS 记录协议（TLS Record）和 TLS 握手协议（TLS Handshake）。较低的层为 TLS 记录协议，位于某个可靠的传输协议（例如 TCP）上面，与具体的应用无关，所以，一般把TLS协议归为传输层安全协议。TLS 的最大优势就在于：TLS 是独立于应用协议。高层协议可以透明地分布在 TLS 协议上面。然而，TLS 标准并没有规定应用程序如何在 TLS 上增加安全性；它把如何启动 TLS 握手协议以及如何解释交换的认证证书的决定权留给协议的设计者和实施者来判断。<br>&emsp;&emsp;SSL是Netscape开发的专门用户保护Web通讯的，而TLS1.0是IETF(工程任务组)制定的一种新的协议，它建立在SSL 3.0协议规范之上，是SSL 3.0的后续版本。两者差别很小，可以理解为SSL 3.1，它是写入了RFC的。为了兼顾各种说法本文将SSL和TLS统称为SSL/TLS，但是请注意，本文所涉及的关于各种协议的解析是基于TLS1.2版本（这是目前使用最广泛的版本）。  <p></p><p></p><h4>区别</h4><br>&emsp;&emsp;SSL和TLS的主要区别如下：  <p></p><ul><li>版本号：TLS记录格式与SSL记录格式相同，但版本号的值不同。</li><li>报文鉴别码：SSLv3.0和TLS的MAC算法及MAC计算的范围不同。TLS使用了RFC-2104定义的HMAC算法。SSLv3.0使用了相似的算法，两者差别在于SSLv3.0中，填充字节与密钥之间采用的是连接运算，而HMAC算法采用的是异或运算。但是两者的安全程度是相同的。</li><li>伪随机函数：TLS使用了称为PRF的伪随机函数来将密钥扩展成数据块，是更安全的方式。</li><li>报警代码：TLS支持几乎所有的SSLv3.0报警代码，而且TLS还补充定义了很多报警代码，如解密失败、记录溢出、未知、拒绝访问等。</li><li>加密计算：TLS与SSLv3.0在计算主密值（master secret）时采用的方式不同。</li><li>填充：用户数据加密之前需要增加的填充字节。在SSL中，填充后的数据长度要达到密文块长度的最小整数倍。而在TLS中，填充后的数据长度可以是密文块长度的任意整数倍（但填充的最大长度为255字节），这种方式可以防止基于对报文长度进行分析的攻击。</li></ul><h2 id="protocol">SSL/TLS协议</h2><p></p><h3>密码套件（cipher suite）</h3><br>&emsp;&emsp;密码套件（Cipher suite）是传输层安全（TLS）/安全套接字层（SSL）网络协议中的一个概念。在TLS 1.2中，密码套件的名称是以协商安全设置时使用的身份验证、加密、消息认证码（MAC）和密钥交换算法组成。TLS 1.3中的密码套件格式已经修改。在目前的TLS 1.3草案文档中，密码套件仅用于协商加密和HMAC算法。在创建一个TLS连接后，一次也称TLS握手协议的握手发生。在这个握手，一条ClientHello和一条ServerHello消息被发出。首先，客户端按照偏好的顺序发送它支持的密码套件的列表。然后服务器回复它从客户端的列表中选择的密码套件。<br>&emsp;&emsp;例如TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,每个密码套件名称定义一个密钥交换算法、一个批量加密算法、一个消息认证码（MAC）算法，以及一个伪随机函数(PRF)  <p></p><ul><li>密钥交换算法，例如ECDHE_RSA，用于决定客户端与服务器之间在握手时如何身份验证</li><li>批量加密算法，例如AES_128_GCM，用于加密消息流。它还包括密钥大小及显式和隐式初始化向量（密码学随机数）的长度</li><li>消息认证码算法，例如SHA256，用于创建消息摘要，消息流每个数据块的加密散列</li><li>伪随机函数，例如TLS 1.2的伪随机函数使用MAC算法的散列函数来创建一个主密钥——连接双方共享的一个48字节的私钥。主密钥在创建会话密钥（例如创建MAC）时作为一个熵来源</li></ul><p>理解密码套件的作用以及组成部分对我们理解握手协议的过程十分重要，因为使用不同的密码套件在握手协议的实现细节上有很大的不同，特别是密钥交换的过程。本文将主要讲解ECDHE_RSA密钥交换算法下的握手过程（也可以理解为三种不同密码套件的握手过程，对于握手过程而言不同套件的差异主要体现在密钥交换的过程，批量加密算法和消息验证码算法的不同主要体现在加密传输的过程，伪随机算法的不同体现在产生分组加密初始向量的过程）。  </p><p></p><h3>记录协议</h3><br>&emsp;&emsp;TLS记录协议位于TLS握手协议的下层，在可靠的传输协议(如TCP/IP)上层。TLS记录协议的一条记录包含长度字段、描述字段和内容字段。TLS记录协议处理数据的加密，即记录协议得到要发送的消息之后，将数据分成易于处理的数据分组，进行数据压缩处理(可选)，计算数据分组的消息认证码MAC，加密数据然后发送数据；接收到的消息首先被解密，然后校验MAC值，解压缩，重组，最后传递给协议的高层客户。记录协议有四种类型的客户：握手协议、警告协议、改变密码格式协议和应用数据协议。通常使用一个对称算法，算法的密钥由握手协议提供的值生成。TLS 记录协议提供的连接安全性具有两个基本特性:  <p></p><ul><li>私有――对称加密用以数据加密（DES 、RC4 等）。对称加密所产生的密钥对每个连接都是唯一的，且此密钥基于另一个协议（如握手协议）协商。记录协议也可以不加密使用  </li><li>可靠――信息传输包括使用密钥的 MAC 进行信息完整性检查。安全哈希功能（ SHA、MD5 等）用于 MAC 计算。记录协议在没有 MAC 的情况下也能操作，但一般只能用于这种模式，即有另一个协议正在使用记录协议传输协商安全参数</li></ul><p></p><h3>握手协议</h3><br>&emsp;&emsp;TLS握手协议处理对等用户的认证，在这一层使用了公共密钥和证书，并协商算法和加密实际数据传输的密钥，该过程在TLS记录协议之上进行。TLS握手协议是TLS协议中最复杂的部分，它定义了10种消息，客户端和服务器利用这10种消息相互认证，协商哈希函数和加密算法并相互提供产生加密密钥的机密数据。TLS记录协议会在加密算法中用到这些加密密钥，从而提供数据保密性和一致性保护。<br>&emsp;&emsp;我们先来分析基于ECDHE_RSA密钥交换算法的握手过程，在这之前先来解释一下ECDHE是什么。ECDHE_RSA = EC（<a href="https://baike.baidu.com/item/%E6%A4%AD%E5%9C%86%E6%9B%B2%E7%BA%BF%E5%AF%86%E7%A0%81%E5%AD%A6/2249951" target="_blank" rel="noopener">椭圆曲线加密算法</a>）+ DH（<a href="https://baike.baidu.com/item/Diffie-Hellman" target="_blank" rel="noopener">Diffie-Hellman密钥交换算法</a>）+ E（临时的temporary）+ RSA（用于签名，防止中间人攻击），所以ECDHE的意思是结合椭圆曲线的生成临时会话密钥的密钥交换算法。对于这个算法的具体计算过程，这里不详细讨论。<br>&emsp;&emsp;下图是EDCHE_RSA密钥交换算法的大致流程，接下来我会结合wireshark抓取的数据包来分析握手的过程：<br><img title="握手过程" alt="握手过程" class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/TLS/overview.PNG?imageView2/2/w/600"><p></p><ul><li>在客户端和服务器开始握手之前先进行TCP三次握手，这部分的内容本文不会讨论。三次握手之后，开始握手协议，先在这展示一下抓到的所有握手包。<img title="handshake" alt="handshake" class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/TLS/handshake.PNG?imageView2/2/w/600"></li><li>client hello：由于客户端对一些加解密算法的支持程度不一样，但是SSL/TLS协议传输过程中必须要求客户端与服务器端使用相同的加解密算法。所以在client hello阶段，客户端要首先告知服务端，自己支持哪些密码套件，客户端将支持的密码套件列表发送给服务端；同时客户端还会产生一个随机数，这个随机数双方都要保存（生成主密钥）；session id字段是用于维持会话，如果客户端与服务端关闭会话之后，客户端又要重新发起会话，session id可用于双方协商是否要进行重新握手过程；extension字段用于添加一些拓展功能；compress表示支持的压缩方法。  <img title="client_hello" alt="client" class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/TLS/client_hello.PNG?imageView2/2/w/600">  </li><li>server hello：server hello是根据客户端发送过来的密码套件和压缩方法选择双方都支持的类型，同时服务器端也会生成一个随机数，双方都要保存。<img title="server_hello" alt="server_hello" class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/TLS/server_hello.PNG?imageView2/2/w/600">  </li><li>certificate：该过程中服务器用私钥签名证书，发送给客户端以认证身份<img title="certificate" alt="certificate" class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/TLS/certificate.PNG?imageView2/2/w/600">  </li><li>server key exchange：对于ECDHE_RSA密钥交换算法来说这一过程是必须的，在此过程服务端将生成一对公钥和私钥，私钥保留（用于服务器端生成预主密钥），并将公钥发送给客户端（用于客户端生成预主密钥），同时将前一阶段所有的会话内容利用私钥进行前面发给客户端，用于验证服务端身份，防止中间人攻击。而对于RSA_RSA密钥交换算法，没有这一过程，同样有这个过程的还有DHE密钥交换算法，有没有这一过程都是却决于密钥交换算法自身。在这个数据包中，还给出了服务端生成公私钥所用的算法sec256r1  <img title="server_key_change" alt="server_key_change" class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/TLS/server_key_change.PNG?imageView2/2/w/600">  </li><li>server hello done：表示server hello结束，这是个空消息  <img title="server_hello_done" alt="server_hello_done" class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/TLS/server_hello_done.PNG?imageView2/2/w/600">  </li><li>client key exchange：客户端也生成一对公钥和私钥，私钥保留（用于客户端生成预主密钥），公钥发给服务端（用于服务端生成预主密钥）  <img title="client_key_exchange" alt="client_key_exchange" class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/TLS/client_key_exchange.PNG?imageView2/2/w/600">  </li><li>change cipher spec：客户端根据交互过程中获得的信息，以及应用服务端规定的密码套件，已经生成了相应的密钥。通过这条消息，客户端告诉服务器端：从现在起，我将使用双方约定的密码规范进行通信  <img title="change_client_cipher" alt="change_client_cipher" class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/TLS/change_client_spec.PNG?imageView2/2/w/600">  </li><li>encrypted handshake message：客户端利用生成的密钥加密一段finishde数据传送给服务端，此数据是为了在正式传输应用之前对刚刚握手建立起来的加解密通道进行验证  <img title="client_finish" alt="client_finish" class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/TLS/client_finish.PNG?imageView2/2/w/600">  </li><li>new session ticket：服务端告知客户端将生成新的session ticket用于保持会话（session ticket与前面提到的session id作用类似，但两者实现方式不同）<img title="new_session_ticket" alt="new_session_ticket" class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/TLS/new_session_key.PNG?imageView2/2/w/600">  </li><li>change cipher spec：同样服务端也要发送这段信息，作用与客户端一致  </li><li>encrypted handshake message：作用与客户端一致<br>至此，握手协议结束，双方开始建立加密通道。  </li></ul><p>&emsp;&emsp;值得注意的是在这个过程中客户端和服务器端都各自产生一对公钥和私钥还有一个随机数，这些都是作为生成预主密钥的元素。预主密钥分别在客户端和服务器端生成，算法的特性能够保证二者生成的预主密钥相同。那么由预主密钥如何生成会话密钥呢，这就要用到前面提到的伪随机函数，通过预主密钥我们将生成客户端验证密钥、服务器端验证密钥、客户端加密密钥、服务器端加密密钥以及客户端分组加密的初始向量和服务器端的分组加密初始向量，具体生成过程可以参考<a href="https://xz.aliyun.com/t/2531" target="_blank" rel="noopener">这篇博客</a>。对基于DH算法和RSA算法的握手过程可以参见下图，也可以参考<a href="https://segmentfault.com/a/1190000002554673" target="_blank" rel="noopener">这篇博客</a>。<br><img title="基于DH算法的握手过程" alt="基于DH算法的握手过程" class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/TLS/diffie_hellman.jpg?imageView2/2/w/600"><br><img title="基于RSA算法的握手过程" alt="基于RSA算法的握手过程" class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/TLS/handshake_rsa.png?imageView2/2/w/600">  </p><p></p><h3>前向安全</h3><br>&emsp;&emsp;在这里有必要提一下关于前向安全的定义：前向安全或前向保密，有时也被称为完美前向安全（Perfect Forward Secrecy，缩写：PFS），是密码学中通讯协议的安全属性，指的是长期使用的主密钥泄漏不会导致过去的会话密钥泄漏。前向安全能够保护过去进行的通讯不受密码或密钥在未来暴露的威胁。如果系统具有前向安全性，就可以保证在主密钥泄露时历史通讯的安全，即使系统遭到主动攻击也是如此。在传输层安全协议（TLS）中，提供了基于迪菲-赫尔曼密钥交换（DHE）的前向安全通讯，分别为（DHE-RSA）和DHE-DSA），还有基于椭圆曲线迪菲-赫尔曼密钥交换（ECDHE）的前向安全通讯，包括（ECDHE-RSA与ECDHE-ECDSA）。理论上，从SSLv3开始，就已经可以使用支持前向安全的密码算法进行通讯。之前我们提到ECDHE算法在sever key exchage阶段会生成一个临时的公私钥对，公钥发送给用户，私钥用于对数据进行RSA签名来验证服务器的身份，如果服务器的私钥泄露，这些会话不会受到影响，无法解密。对于有些算法而言，它在握手过程中不会有这个生成公私钥对的过程，它将使用服务器的私钥进行签名。如果服务器的私钥泄露，这些会话都将被暴露，这就是所谓的前向安全。<p></p><h2 id="openssl">openssl</h2>]]></content:encoded>
      
      <comments>https://chaoge123456.github.io/TLS.html/#disqus_thread</comments>
    </item>
    
    <item>
      <title>K近邻算法详解</title>
      <link>https://chaoge123456.github.io/KNN.html/</link>
      <guid>https://chaoge123456.github.io/KNN.html/</guid>
      <pubDate>Fri, 03 Aug 2018 06:14:23 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;&lt;strong&gt;摘要:&lt;/strong&gt; K近邻（简称KNN）是一种基于统计的数据挖掘算法，它是在一组历史数据记录中寻找一个或者若干个与当前记录最相似的历史记录的特征值来预测当前记录的未知的特征值，因此具有直观、无需先验统计知识等特点，同时K近邻算法适用于分类和回归两种不同
        
      
      </description>
      
      <content:encoded><![CDATA[<p><strong>摘要:</strong> K近邻（简称KNN）是一种基于统计的数据挖掘算法，它是在一组历史数据记录中寻找一个或者若干个与当前记录最相似的历史记录的特征值来预测当前记录的未知的特征值，因此具有直观、无需先验统计知识等特点，同时K近邻算法适用于分类和回归两种不同的应用场景，本文主要介绍K近邻算法在回归任务场景下的应用。<br><img alt="K近邻算法概述" class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/KNN/KNN.jpg?imageView2/2/w/600"></p><h1 id="文章概览"><a href="#文章概览" class="headerlink" title="文章概览"></a>文章概览</h1><ul><li><a href="#KNN">K近邻概述</a></li><li><a href="#element">K近邻三要素</a><ul><li>距离度量</li><li>K值选择</li><li>分类决策规则</li></ul></li><li><a href="#achieve">K近邻的实现</a><ul><li>线性查找</li><li>空间分割<ul><li>kd树的生成</li><li>kd树的搜索</li><li>scikit_learn中的K近邻算法</li></ul></li></ul></li><li><a href="#problem">总结</a></li></ul><h2 id="KNN">K近邻概述</h2><p>&emsp;&emsp;K近邻算法简单直观，下面举一个简单的例子帮助大家理解。在一个城市当，居住着许多不同民族的居民，相同民族的人们大多聚集在一起，形成一个小型的部落。现在你想知道其中一个部落是属于哪个民族的，并且你已经掌握很多关于部落和民族的信息，你会怎么做？其实我们可以通过观察这个部落的人们的生活习惯、节日风俗、衣着服饰等特点，在与我们掌握其他部落的特点进行对比，找出与该部落在这些方面最接近的几个部落（已知这几个部落分别属于哪个民族），如果这几个部落的多数属于哪个民族，那么在很大程度上我们可以猜测该部落可能也属于这个民族，从而得到我们想要的答案。<br>&emsp;&emsp;对于K近邻稍微正式一点的描述是：给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最近邻的K个实例，这K个实例的多数属于某个类，就把该输入实例分为这个类。从这段描述中我们可以看出，K近邻算法的学习过程只是简单的存储已知的训练数据，当遇到新的查询实例时，再从存储器中取出一系列相似的实例，用来分类新的查询实例。我们把K近邻算法的这种分类特点称为消极学习方法,具有同样特点的学习算法还有局部加权回归，它的优点在于不是在整个实例空间上一次性的估计目标函数，而是针对每个待分类的新实例做出局部的和相异的估计。而与之对应的分类算法，我们称之为积极学习方法，例如：支持向量机、神经网络等等，它的特点是在新的查询实例到来之前，通过训练实例总结归纳出相似判断的目标函数。<br>&emsp;&emsp;K近邻同样可以应用于回归任务。K近邻做分类预测时，一般是选择多数表决法，即训练集里和预测的样本特征最近的K个样本，预测为里面有最多类别数的类别。而K近邻做回归时，一般是选择平均法，即最近的K个样本的样本输出的平均值作为回归预测值。由于两者区别不大，虽然本文主要是讲解K近邻的分类方法，但思想对K近邻的回归方法也适用。</p><h2 id="element">K近邻三要素</h2><p></p><h3>距离度量</h3><br>&emsp;&emsp;回到刚才那个例子，我们假设从生活习惯、节日风俗、衣着服饰、宗教信仰等多个方面来考察部落之间的相似程度。所谓的相似程度用另外一种说法来表达即差异，差异越小，相似程度越大。在机器学习中，我们使用距离来度量差异。一般情况下我们采用欧式距离来度量差异（其他的距离度量方式如曼哈顿距离等同样适用）。<br><strong>欧式距离：</strong> 设特征空间\({\chi}\)是\(n\)维实数向量空间\(R^n,x_i,x_j\)属于\({\chi}\)，\(x_i=(x^1_i,x^2_i,…,x^n_i),x_j=(x^1_j,x^2_j,…,x^n_j),x_i,x_j\)的欧式距离定义为<br>$$\sqrt{\sum_{l=1}^{n}|x_i^l-x_j^l|^2}$$<br>&emsp;&emsp;刚才说到我们将通过生活习惯、节日风俗、衣着服饰、宗教信仰等多个方面来考察部落之间的相似程度，但是现在我们需要考虑这样一种情况，我们观察发现这些部落虽然在有些方面存在很大的差异，但是这些差异却不能成为区分不同民族的依据，比如说，A和B两个部落都属于C民族，但是A部落信仰D教，B部落信仰E教。也就是说，应用k-近邻的一个实践问题是，实例间的距离是根据实例的所有属性计算的，但是这些属性当中存在着对分类无关的属性，这些无关的属性可能在实例空间中相距很远，这样一来近邻间的距离会被大量的不相关属性所支配。这种由于存在很多不相关属性所导致的难题，有时被称为维度灾难。解决该问题的一个方法是，当计算两个实例间的距离时对每个属性加权，从不断的测试中获得启发，给对分类影响大的属性赋予更高的权值。<p></p><p></p><h3>K值选择</h3><br>&emsp;&emsp;K值的选择会对K近邻法的结果产生巨大的影响。如果选择较小的K值，学习的近似误差会减小，只有与输入实例较近的训练实例才会对预测结果起作用，这样做存在的问题是预测结果对近邻点过于敏感，如果近邻点恰巧是噪声，预测结果就会出错。如果选择较大的K值，其优点是可以减少学习得估计误差，缺点是与输入实例较远的训练实例也会对预测起作用。K值选择的原则往往是经过大量独立测试数据、多个模型来验证最佳选择。<p></p><p></p><h3>分类决策规则</h3><br>&emsp;&emsp;K近邻中的分类决策往往是多数表决，即由输入实例的K个近邻的训练实例中的多数类决定输入实例的类。这样的决策规则存在一个问题，假设我们现在已知A、B两个部落属于同一个民族，C、D、E三个部落属于同一个民族。为了测试我们的模型，我们将A部落作为实例，输入到模型中进行测试，K值设为4。经过计算我们发现，得到的K个近邻实例分别为B、C、D、E，并且A、B部落之间的特征距离很小，而A与C、D、E三个部落之间的特征距离很大。但是由于分类决策规则是依据多数进行表决的，所以我们最终会将A判断为与C、D、E部落相同的民族。由此可以看出，多数表决的决策规则是不合理的。解决这一问题的方法是对距离进行加权，B部落与A部落的差异比较小，所以在K个实例当中B部落应该对最终的决策产生更大的影响，而距离越远影响力越小。<p></p><h2 id="achieve">K近邻的实现</h2><p></p><h3>线性查找</h3><br>&emsp;&emsp;K近邻的核心思想是寻找与输入实例距离最近的K个实例，那么一个最朴素的想法是计算输入实例和所有训练实例之间的距离，然后从中挑选出距离最近的K个实例，这就是线性查找的思想，具体实现如下（大家可以在我的<a href="https://github.com/chaoge123456/machine_learning_achieve" target="_blank" rel="noopener">github</a>中找到本文所有的源代码）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment">#_*_ coding:utf-8 _*_</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#通过直接对k-近邻算法的描述来构建鸢尾花数据集的模型，并利用该模型对鸢尾花类型进行预测</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"><span class="keyword">from</span> init_data <span class="keyword">import</span> load_data</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">data_split</span><span class="params">()</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    data_split函数的主要作用是将原始数据分为训练数据和测试数据，其中训练数据和测试数据的比例为2：1</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    x_data,y_data = load_data()</span><br><span class="line">    x_training = []</span><br><span class="line">    x_test= []</span><br><span class="line">    y_training = []</span><br><span class="line">    y_test = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(x_data)):</span><br><span class="line">        <span class="keyword">if</span> random.random() &gt; <span class="number">0.67</span>:</span><br><span class="line">            x_training.append(x_data[i])</span><br><span class="line">            y_training.append(y_data[i])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            x_test.append(x_data[i])</span><br><span class="line">            y_test.append(y_data[i])</span><br><span class="line">    x_training = np.array(x_training)</span><br><span class="line">    y_training = np.array(y_training)</span><br><span class="line">    x_test = np.array(x_test)</span><br><span class="line">    y_test = np.array(y_test)</span><br><span class="line">    <span class="keyword">return</span> (x_training,x_test,y_training,y_test)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">euclidean_distance</span><span class="params">(x_training,row)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    euclidean_distance函数的主要功能是计算每一条测试数据和训练数据集的欧式距离</span></span><br><span class="line"><span class="string">    :param x_training: 训练数据集</span></span><br><span class="line"><span class="string">    :param row: 一条测试数据</span></span><br><span class="line"><span class="string">    :return: 表示欧式距离的矩阵</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    dis = np.sum((row - x_training)**<span class="number">2</span>,axis=<span class="number">1</span>)</span><br><span class="line">    dis = np.sqrt(dis)</span><br><span class="line">    <span class="keyword">return</span> dis</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(dis,y_training,k)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    predict函数的主要作用是通过计算所得的欧式距离的集合，从中选取k个距离最小的数据点，统计这k个数据点中各个类别所出现的次数，出现次数最多的类别即为预测值</span></span><br><span class="line"><span class="string">    :param dis: 表示欧式距离的矩阵</span></span><br><span class="line"><span class="string">    :param y_training: 训练数据的类别</span></span><br><span class="line"><span class="string">    :param k: 选取k个距离最近的数据</span></span><br><span class="line"><span class="string">    :return: 预测值</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    dis_sort = np.argsort(dis)<span class="comment">#对欧式距离集合进行排序，返回的dis_sort表示的是排序（从小到大）后的数据在原数组中的索引</span></span><br><span class="line">    statistics = &#123;&#125;<span class="comment">#定义字典，用于统计k个数据点中各个类别的鸢尾花出现的次数</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">        rank = dis_sort[i]</span><br><span class="line">        <span class="keyword">if</span> y_training[rank] <span class="keyword">in</span> statistics:</span><br><span class="line">            statistics[y_training[rank]] = statistics[y_training[rank]] + <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            statistics[y_training[rank]] = <span class="number">1</span></span><br><span class="line">    sort_statis = sorted(statistics.items(), key=operator.itemgetter(<span class="number">1</span>), reverse=<span class="keyword">True</span>)<span class="comment">#对statistics字典按照value进行排序（从大到小）</span></span><br><span class="line">    y_predict = sort_statis[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> y_predict</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line"></span><br><span class="line">    x_training, x_test, y_training, y_test = data_split()</span><br><span class="line">    num = <span class="number">0</span></span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> x_test:</span><br><span class="line">        dis = euclidean_distance(x_training,row)</span><br><span class="line">        y_predict = predict(dis,y_training,<span class="number">5</span>)</span><br><span class="line">        <span class="keyword">if</span> y_predict == y_test[i]:</span><br><span class="line">            num = num + <span class="number">1</span></span><br><span class="line">        i = i + <span class="number">1</span></span><br><span class="line">    print(<span class="string">'The accuracy is &#123;0:1f&#125;%'</span>.format(num/i))</span><br></pre></td></tr></table></figure><p></p><p></p><h3>空间分割</h3><br>&emsp;&emsp;基于线性查找的思想，存在一个严重的问题是，如果训练集合很大，计算非常耗时，这种方法在实际中难以应用。为了提高K近邻的搜索效率，我们考虑将搜索空间进行分割，通过这种方法来提高搜索效率，减少计算距离的次数。具体的方法有很多，这里主要介绍kd树。<br>&emsp;&emsp;关于kd树的算法和结构定义大家可以参考<a href="https://github.com/yuanliangding/books/blob/master/%E8%AE%A1%E7%AE%97%E6%9C%BA%7C%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%7C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95(%E6%9D%8E%E8%88%AA" target="_blank" rel="noopener">《统计学习方法》</a>.pdf)和<a href="https://www.joinquant.com/post/2843" target="_blank" rel="noopener">这篇博文</a>,<br>本文主要关注kd树python实现的一些细节问题。<p></p><h4>kd树的生成</h4><ul><li>每次对子空间的划分时，怎样确定在哪个维度上进行划分：在《统计学习方法》中采用的是轮流的方式，即如果这次选择了在第i维上进行数据划分，那下一次就在第j(j≠i)维上进行划分，例如：j = (i mod k) + 1。但是这样忽略了不同属性数据之间的分散程度，有的属性值比较分散，有的属性值比较集中，如果我们以数据分布比较分散的属性作为数据分割的依据，可以更大程度的分割数据，这样更有利于提高搜索的效率。方差可以衡量数据集合的分散程度，所以一般情况下我们采用最大方差分割法对数据集合进行分割。</li><li>以下是kd树生成算法的python描述，代码标注了详细的解释，可以在我的<a href="https://github.com/chaoge123456/machine_learning_achieve" target="_blank" rel="noopener">github</a>中找到完整的代码。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">splitdata</span><span class="params">(data)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    splitdata函数的作用是对输入数据集合进行分割，具体规则：求出方差值最大的那一维特征，然后将整个数据集合根据这一维特征进行排序，中位数为分割点</span></span><br><span class="line"><span class="string">    :param data: 数据集合</span></span><br><span class="line"><span class="string">    :return: 分割数据的属性，数据分割点，分割后两个部分的数据集合</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    n,m = np.shape(data) <span class="comment">#获取numpy矩阵维度</span></span><br><span class="line">    right_data = []</span><br><span class="line">    left_data = []</span><br><span class="line">    num = <span class="number">0</span></span><br><span class="line">    row_mean = np.sum(data,axis=<span class="number">0</span>) / n <span class="comment">#求矩阵每一列的平均值</span></span><br><span class="line">    row_variance = np.sum((data - row_mean)**<span class="number">2</span>,axis=<span class="number">0</span>) <span class="comment">#求矩阵每一列的方差</span></span><br><span class="line">    max_row_variance = np.where(row_variance == np.max(row_variance))[<span class="number">0</span>][<span class="number">0</span>] <span class="comment">#方差值最大的那一列的索引</span></span><br><span class="line">    sort_data = np.argsort(data,axis=<span class="number">0</span>) <span class="comment">#data矩阵按照列排序，返回排序后的对应的索引</span></span><br><span class="line">    split_row = sort_data[:,max_row_variance] <span class="comment">#方差值最大的那一列排序后的索引值</span></span><br><span class="line">    split_index = int(n/<span class="number">2</span>) <span class="comment">#中位数</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> split_row: <span class="comment">#将data中的数据分成两个部分，索引排在中位数之前的放进left_data,反之放进right_data</span></span><br><span class="line">        <span class="keyword">if</span> num &gt; split_index:</span><br><span class="line">            <span class="keyword">if</span> right_data == []:</span><br><span class="line">                right_data = data[line,:]</span><br><span class="line">                right_data = np.array([right_data])</span><br><span class="line">            <span class="keyword">else</span>: right_data = np.concatenate((right_data,[data[line,:]]),axis=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">elif</span> num &lt; split_index:</span><br><span class="line">            <span class="keyword">if</span> left_data == []:</span><br><span class="line">                left_data = data[line,:]</span><br><span class="line">                left_data = np.array([left_data])</span><br><span class="line">            <span class="keyword">else</span>: left_data = np.concatenate((left_data,[data[line,:]]),axis=<span class="number">0</span>)</span><br><span class="line">        num = num + <span class="number">1</span> <span class="comment">#用于计数</span></span><br><span class="line">    split_data = data[split_row[split_index]] <span class="comment">#取对应原始数据中的分割点值</span></span><br><span class="line">    print(<span class="string">"分割结点为："</span>,split_data,<span class="string">"--------- 分割维度为："</span>,max_row_variance)</span><br><span class="line">    <span class="keyword">return</span>(max_row_variance,split_data,right_data,left_data) <span class="comment">#返回值分别为分割数据的属性，数据分割点，分割后两个部分的数据</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KNode</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    定义节点类</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,row = None,point = None,right = None,left = None,parent = None)</span>:</span></span><br><span class="line">        self.row = row <span class="comment">#分割数据集合的特征</span></span><br><span class="line">        self.point = point <span class="comment">#数据分割点</span></span><br><span class="line">        self.right = right <span class="comment">#右子树</span></span><br><span class="line">        self.left = left <span class="comment">#左子树</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_tree</span><span class="params">(dataset,knode)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    create_tree函数的主要作用是通过递归的方式来建立kd树</span></span><br><span class="line"><span class="string">    :param dataset: 数据集合</span></span><br><span class="line"><span class="string">    :param knode: 根结点</span></span><br><span class="line"><span class="string">    :return: 返回kd树</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    length = len(dataset)</span><br><span class="line">    <span class="keyword">if</span> length == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    row,point,right_data,left_data = splitdata(dataset)</span><br><span class="line">    knode = KNode(row,point)</span><br><span class="line">    knode.right = create_tree(right_data,knode.right)</span><br><span class="line">    knode.left = create_tree(left_data,knode.left)</span><br><span class="line">    <span class="keyword">return</span> knode</span><br></pre></td></tr></table></figure></li></ul><p></p><h4>kd树的搜索</h4><p></p><ul><li>kd树的搜索分为两个过程，首先找出包含输入实例的叶子结点，然后在从叶子结点回溯寻找K个近邻实例。在寻找叶子结点的过程中，我们会建立三个列表，一个列表用于存储搜索路径，一个列表用于存储K个近邻点，另外一个列表用于存储K个近邻点所对应的与输入实例的距离，在搜索叶子结点的过程中就计算K近邻点有利于简化回溯过程的搜索。在该过程中，每到达一个结点，我们先将该结点加入搜索路径，然后计算该结点与输入实例之间的距离，如果K近邻点列表中不足K个结点，直接将该结点加入K近邻点列表，同时将计算的距离加入对应的距离列表；如果K近邻列表中已经有K个结点，则选择距离列表中距离最大值与该结点计算的距离进行比较。如果该结点的距离小，则删除最大距离对应的结点，加入该结点，反之无需改变。</li><li>kd树的回溯过程稍微麻烦一点,大家可以参照我给出的代码注释进行理解。在看代码的时候一定要学会去调试，可以帮助我们理解。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_KNN</span><span class="params">(point,kdtree,k)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    k近邻查找</span></span><br><span class="line"><span class="string">    :param point: 测试数据点</span></span><br><span class="line"><span class="string">    :param kdtree: 建立好的kd树</span></span><br><span class="line"><span class="string">    :param k: k值</span></span><br><span class="line"><span class="string">    :return: k个近邻点</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    current = kdtree <span class="comment">#当前节点</span></span><br><span class="line">    nodelist = [] <span class="comment">#搜索路径</span></span><br><span class="line">    nodek = [] <span class="comment">#存储k个近邻点与测试数据点之间的距离</span></span><br><span class="line">    nodek_point = [] <span class="comment">#存储k个近邻点对应的值</span></span><br><span class="line">    min_dis = euclidean_distance(point,kdtree.point)</span><br><span class="line">    print(<span class="string">"---------------------------------------------------------------------------------------"</span>)</span><br><span class="line">    <span class="keyword">while</span> current: <span class="comment">#找到测试点所对应的叶子结点，同时将搜索路径中的结点进行k近邻判断</span></span><br><span class="line">        nodelist.append(current) <span class="comment">#将当前结点加入搜索路径</span></span><br><span class="line">        dis = euclidean_distance(point,current.point)</span><br><span class="line">        <span class="keyword">if</span> len(nodek) &lt; k: <span class="comment">#nodek中不足k个结点时，直接将当前结点加入nodek_point</span></span><br><span class="line">            nodek.append(dis)</span><br><span class="line">            nodek_point.append(current.point)</span><br><span class="line">            print(current.point,<span class="string">"加入k近邻列表"</span>)</span><br><span class="line">        <span class="keyword">else</span>: <span class="comment">#nodek中有k个结点时，删除距离最大的哪个结点，再将该结点加入nodek_point</span></span><br><span class="line">            max_dis = max(nodek)</span><br><span class="line">            <span class="keyword">if</span> dis &lt; max_dis:</span><br><span class="line">                index = nodek.index(max_dis)</span><br><span class="line">                print(current.point, <span class="string">"加入k近邻列表;"</span>,nodek_point[index],<span class="string">"离开k近邻列表"</span>)</span><br><span class="line">                <span class="keyword">del</span>(nodek[index])</span><br><span class="line">                <span class="keyword">del</span>(nodek_point[index])</span><br><span class="line">                nodek.append(dis)</span><br><span class="line">                nodek_point.append(current.point)</span><br><span class="line">        ind = current.row <span class="comment">#该结点进行分割时的特征</span></span><br><span class="line">        <span class="keyword">if</span> point[ind] &gt;= current.point[ind]:</span><br><span class="line">            current = current.right</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            current = current.left</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> nodelist: <span class="comment">#回溯寻找k近邻</span></span><br><span class="line"></span><br><span class="line">        back_point = nodelist.pop()</span><br><span class="line">        ind = back_point.row</span><br><span class="line">        max_dis = max(nodek)</span><br><span class="line">        <span class="keyword">if</span> len(nodek) &lt; k <span class="keyword">or</span> abs(point[ind] - back_point.point[ind])&lt;max_dis: <span class="comment">#如果nodek_point中存储的节点数少于k个，或者测试数据点和当前结点在分割特征维度上的差值的绝对值小于k近邻中的最大距离</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> point[ind] &lt;= back_point.point[ind]: <span class="comment">#注意理解这一段判断的代码，因为在之前寻找叶子结点的过程中，我们决定搜索路径的判断方法是大于即搜索右子树，小于即搜索左子树，这里的判断恰恰相反，是为了遍历之前没有搜索的结点</span></span><br><span class="line">                current = back_point.right</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                current = back_point.left</span><br><span class="line">            <span class="keyword">if</span> current:</span><br><span class="line">                nodelist.append(current)</span><br><span class="line">                dis = euclidean_distance(point,current.point)</span><br><span class="line">                <span class="keyword">if</span> max_dis &gt; dis <span class="keyword">and</span> len(nodek) == k:</span><br><span class="line">                    index = nodek.index((max_dis))</span><br><span class="line">                    print(current.point, <span class="string">"加入k近邻列表;"</span>, nodek_point[index], <span class="string">"离开k近邻列表"</span>)</span><br><span class="line">                    <span class="keyword">del</span>(nodek[index])</span><br><span class="line">                    <span class="keyword">del</span> (nodek_point[index])</span><br><span class="line">                    nodek.append(dis)</span><br><span class="line">                    nodek_point.append(current.point)</span><br><span class="line">                <span class="keyword">elif</span> len(nodek) &lt; k:</span><br><span class="line">                    nodek.append(dis)</span><br><span class="line">                    nodek_point.append(current.point)</span><br><span class="line">                    print(current.point, <span class="string">"加入k近邻列表"</span>)</span><br><span class="line">    <span class="keyword">return</span> nodek_point</span><br></pre></td></tr></table></figure></li></ul><p></p><h4>scikit_learn中的K近邻算法</h4><br>scikit_learn中的K近邻算法的具体解释大家可以参照<a href="http://sklearn.apachecn.org/cn/latest/modules/neighbors.html#k-d" target="_blank" rel="noopener">scikit_learn官网</a>的文档，这里给出一段利用scikit_learn解决鸢尾花数据集的代码。这篇文章中给出的代码都是基于UCI鸢尾花数据集实现的，大家可以比较一下这三种实现方式的预测准确率。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment">#_*_ coding:utf-8 _*_</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#通过sklearn库中所提供的关于k-近邻算法相关的包来实现对鸢尾花数据集的建模与预测</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> init_data <span class="keyword">import</span> load_data</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">x_data,y_data = load_data() <span class="comment">#获取数据</span></span><br><span class="line">x_training,x_test,y_training,y_test = train_test_split(x_data,y_data,random_state=<span class="number">10</span>) <span class="comment">#将数据分为训练集和测试集</span></span><br><span class="line">estimotor = KNeighborsClassifier() <span class="comment">#构造k-近邻分类器</span></span><br><span class="line">estimotor.fit(x_training,y_training) <span class="comment">#训练模型</span></span><br><span class="line">y_predicted = estimotor.predict(x_test) <span class="comment">#用训练的模型进行预测</span></span><br><span class="line">accuracy = np.mean(y_test == y_predicted)*<span class="number">100</span> <span class="comment">#计算预测结果的准确率</span></span><br><span class="line">print(<span class="string">'The accuracy is &#123;0:1f&#125;%'</span>.format(accuracy))</span><br></pre></td></tr></table></figure><p></p><p></p><h2 id="problem">总结</h2><br>K近邻算法的优点在于<p></p><ul><li>算法简单直观，易于实现</li><li>K近邻在进行类别决策时只于少量的相邻样本有关，可以避免样本数量不平衡问题</li><li>K近邻最直接的利用了样本之间的关系，减少了类别特征选择不当对分类结果造成的不利影响，可以最大程度减少分类过程中的误差项  </li></ul><p>同时K近邻算法存在的问题也很突出</p><ul><li>当样本数量大、特征多的时候计算量非常大</li><li>样本不平衡的时候，对稀有类别的预测准确率降低</li><li>预测速度慢  </li></ul><p>&emsp;&emsp;花了两天的时间找资料、写代码，又花了一天的时间写文章，终于结束了！有一点不太满意的地方是对kd树的回溯没有进行详尽的描述，原因是真的找不出一种好的描述方法，文字描述看起来累，用图表的话工作量太大，大家可以看看我推荐的博文结合代码，理解起来也不会太难。好了，到这里结束了，好好加油，坚持！</p>]]></content:encoded>
      
      <comments>https://chaoge123456.github.io/KNN.html/#disqus_thread</comments>
    </item>
    
    <item>
      <title>搭建博客：HEXO+GITHUB+CODING</title>
      <link>https://chaoge123456.github.io/hex.html/</link>
      <guid>https://chaoge123456.github.io/hex.html/</guid>
      <pubDate>Tue, 31 Jul 2018 13:30:00 GMT</pubDate>
      <description>
      
        
        
          &lt;p&gt;&lt;strong&gt;摘要:&lt;/strong&gt; 进入计算机行业已经好几年了，这么多年的摸爬滚打，我终于意识到了一个血的教训:好记性不如烂键盘!当我们遇到问题并解决问题之后，我们应该及时的把我们处理问题的过程记录下来，一来可以防止我们在此遇到同样的问题时又要重复造轮子，二来可以为遇
        
      
      </description>
      
      <content:encoded><![CDATA[<p><strong>摘要:</strong> 进入计算机行业已经好几年了，这么多年的摸爬滚打，我终于意识到了一个血的教训:好记性不如烂键盘!当我们遇到问题并解决问题之后，我们应该及时的把我们处理问题的过程记录下来，一来可以防止我们在此遇到同样的问题时又要重复造轮子，二来可以为遇到同样问题的小伙伴提供经验，所以对于我们来说有一个属于自己的博客尤为重要。本文记录的是搭建hexo个人博客平台过程中遇到的一些问题和心得，希望能对小伙伴们有所启发。<br><img alt="hexo和github" class="class1 class2" src="http://pcvm1j2f3.bkt.clouddn.com/static/images/KNN/hexo.png?imageView2/2/w/600">  </p><h1 id="文章概览"><a href="#文章概览" class="headerlink" title="文章概览"></a>文章概览</h1><ul><li><a href="#overview">HEXO简介</a><ul><li>静态博客与动态博客</li><li>基本流程</li><li>运行机制</li></ul></li><li><a href="#next">HEXO NEXT主题美化</a></li><li><a href="#github">HEXO部署到GITHUB</a></li><li><a href="#search">提交搜索引擎</a><ul><li>提交谷歌搜索引擎</li><li>提交百度搜索引擎</li></ul></li><li><a href="#end">总结</a></li></ul><p></p><h2 id="overview">HEXO简介</h2><br><a href="https://hexo.io/zh-cn/" target="_blank" rel="noopener">Hexo</a>是一个基于node.js开发的快速、简洁且高效的静态博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。<br>hexo具有以下这些特性：<p></p><ul><li>hexo基于node.js，非常小巧，安装部署简单</li><li>hexo开源，主题丰富，插件丰富，自定义能力强</li><li>hexo支持markdown语法，易于博客写作</li><li>hexo是纯静态博客，不需要数据库支持</li></ul><p></p><h3>静态博客系统与动态博客系统</h3><br>一个网站最基础的部分就是网页，如果想从HTML页面写起，显然成本太高，好在大牛们已经做好了博客生成器来解决网页编写的问题。一般来说，博客生成器分为动态和静态两种。其中，动态博客生成器典型代表有：WordPress、FarBox、Ghost等，静态的博客生成器典型代表有：Hexo、Jekyll、Octopress、Hugo等。关于动态和静态的区别主要有以下几点：<p></p><ul><li>资源占用上，静态博客相对于动态博客占用服务器资源少，可以托管在github pages上，而动态博客往往需要一台相对独立的服务器  </li><li>数据管理和更新操作上，由于动态博客有独立的数据库和后台管理系统，对资源的管理和发布相对比较容易；而静态博客往往需要一些第三方平台的支持，如评论系统以及图床，数据管理更新比较繁琐。  </li><li>安全性上，静态博客比动态博客安全性更好</li></ul><p></p><h3>基本流程</h3><br>&emsp;&emsp;这里我大致叙述一下搭建hexo博客系统的大致流程。我们首先要搭建hexo博客系统的开发环境，这里我主要讲解windows环境下的安装配置，其他系统的安装配置可以参考<a href="https://hexo.io/zh-cn/docs/index.html" target="_blank" rel="noopener">官方文档</a>。<br><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">安装git</span><br><span class="line">安装<span class="keyword">node</span>.<span class="title">js</span></span><br><span class="line">执行命令 npm install -g hexo-cli（安装hexo命令行工具）</span><br><span class="line">执行命令 hexo init [文件夹名]</span><br><span class="line">进入刚才初始化的文件夹，执行命令 npm install 即创建了一个原始的hexo博客系统</span><br><span class="line">执行命令 hexo g 生成站点文件</span><br><span class="line">执行命令 hexo d 把博客部署到站点</span><br></pre></td></tr></table></figure><p></p><p></p><h3>运行机制</h3><br>&emsp;&emsp;首先我们来分析一下hexo文件夹的结构  <p></p><ul><li><strong>_config.yml</strong>:站点的配置文件</li><li><strong>db.json</strong>:缓存文件</li><li><strong>node_modules</strong>:安装的插件以及hexo所需要的一些node.js模块</li><li><strong>package.json</strong>：应用程序信息，配置hexo运行需要的js包</li><li><strong>public</strong>：生成的站点文件</li><li><strong>scaffolds</strong>：模板文件夹，新建文章时，会默认包含对应模板内容</li><li><strong>source</strong>：资源文件夹是存放用户资源的地方。所有的源文件都会被保存在_post文件夹中</li><li><strong>themes</strong>：hexo站点所使用的主题  </li></ul><p>&emsp;&emsp;为了搞清楚hexo的运行机制，我们有必要了解一下hexo的模板引擎（hexo使用的模板引擎是ejs编写的），模板引擎的作用就是将界面与数据分离最简单的原理是将模板内容中指定的地方替换成数据，实现业务代码与逻辑代码分离。我们可以注意到，在hexo中，source文件夹和themes文件夹是同级的，我们可以将source文件夹理解为数据库，而主题文件夹相当于界面，当执行<strong>hexo g</strong>命令时，就相当于将数据嵌入到界面中，生成静态文件public。<br>&emsp;&emsp;具体来说在hexo中，从markdown文件到生成html的过程中大致经历了两次渲染的过程：</p><ol><li>通过解析markdown文件，并结合站点配置文件和source目录下的相关文件，生成相应的数据对象</li><li>将生成的数据对象嵌入到themes主题中的渲染引擎生成站点文件<br><img src="/images/hexo.PNG" alt="hexo运行机制"></li></ol><p></p><h2 id="next">HEXO NEXT主题美化</h2><br>&emsp;&emsp;基于hexo博客系统的主题有很多，你可以在<a href="https://hexo.io/themes/" target="_blank" rel="noopener">这里</a>找到你喜欢的主题。我的博客采用的是next主题，我个人觉得next主题看上去简洁大方，用起来很舒服。这里我不会详细的介绍next主题的配置过程，我会分享一些我在配置过程中遇到的一些问题。<p></p><ul><li>next主题的<a href="https://theme-next.iissnan.com/" target="_blank" rel="noopener">官方网站</a>详细阐述了主题的基本配置过程，我也是参照它一步步进行配置的</li><li>在配置主题之前推荐大家安装一款node.js的开发工具，有利于提高效率。我安装的是webstorm，它也支持markdown文件的编写，强烈推荐（这个公司提供的开发工具都很强大，pycharm也是这个公司的产品之一）。</li><li>在配置主题的过程中要注意区分两个配置文件，一个是主题的配置文件_config.yml，一个是站点的配置文件_config.yml。因为有些配置操作实在主题的配置文件中进行的，有的实在站点的配置文件进行的，一定不能弄混了。</li><li>推荐一篇<a href="http://shenzekun.cn/hexo%E7%9A%84next%E4%B8%BB%E9%A2%98%E4%B8%AA%E6%80%A7%E5%8C%96%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B.html" target="_blank" rel="noopener">next主题美化的博文</a></li><li>对主题进行配置时，我的建议是每修改一项之后都在本地运行一下（先运行<strong>hexo g</strong>命令，在运行<strong>hexo s</strong>命令，在浏览器中查看），看看有没有出错，这样我们可以及时找到出错的地方。</li><li>hexo的配置文件是yaml格式的，它通过缩进来表示层级关系，修改配置文件时要主要缩进问题</li></ul><p></p><h2 id="github">HEXO部署到GITHUB</h2><br>&emsp;&emsp;在对主题修改完成之后，下一步的工作就是将hexo部署到github pages。在部署之前，需要做好一些准备工作，具体的操作过程可以参考<a href="https://zhuanlan.zhihu.com/p/26625249" target="_blank" rel="noopener">这篇博客</a>。<p></p><ol><li>注册github账号，<a href="http://wiki.jikexueyuan.com/project/git-tutorial/remote-repository.html" target="_blank" rel="noopener">添加ssh key</a></li><li>在github中新建仓库，仓库名为：<strong>username.github.io</strong></li><li>修改站点配置文件的deploy选项</li><li>执行命令<strong>hexo deploy</strong>  </li></ol><p>&emsp;&emsp;在这些操作过程中我们需要注意一些问题：</p><ul><li>在deploy的过程中可能会出现速度过慢的问题，这是由于GFW对github的限制造成的，可以通过代理或者修改hosts文件来提高访问速度</li><li>有时候会因为一些莫名其妙的问题导致deploy失败，无法解决这一问题时，我们可以通过复制生成的public文件，通过git提交到远程仓库，为了使整个过程更加自动化，我们可以在根目录下写一个脚本文件deploy.sh  <figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hexo <span class="keyword">generate</span>  </span><br><span class="line">cp -R public<span class="comment">/* chaoge123456.github.io  </span></span><br><span class="line"><span class="comment">cd chaoge123456.github.io  </span></span><br><span class="line"><span class="comment">git add .  </span></span><br><span class="line"><span class="comment">git commit -m “update”  </span></span><br><span class="line"><span class="comment">git push origin master</span></span><br></pre></td></tr></table></figure></li></ul><p>每次提交更新时只需要在根目录下执行命令：<strong>./deploy.sh</strong>即可  </p><p></p><h2 id="search">提交搜索引擎</h2><br>&emsp;&emsp;部署完成之后，现在我们可以通过浏览器访问到我们的博客，但是还有一件非常重要的事我们需要去完成。虽然我们可以通过浏览器访问到我们的博客，但是我们无法通过搜索引擎搜索到我们的博客，所以我们需要将我们的博客地址提交给搜索引擎。这时我们需要注意，github屏蔽了百度搜索引擎的爬虫，这也就意味着通过百度是无法搜索到我们在github上的博客（googl不存在这样的问题）。所以为了在国内也能访问到我们的博客，我们需要将我们的博客托管到国内的类似于github的平台——<a href="https://coding.net/" target="_blank" rel="noopener">coding</a>（coding的博客地址和github的博客地址不一样，所以接下来我们需要做的是将github的博客地址提交给google，将coding的地址提交给百度）。部署到coding的流程跟github类似，为了将站点同时更新到coding和github，我们需要在站点配置文件下的deploy选项的repo同时添加github和coding的远程仓库<br><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">deploy</span>:  </span><br><span class="line">  <span class="attribute">type</span>: git  </span><br><span class="line">  <span class="attribute">repo</span>:  </span><br><span class="line">    <span class="attribute">github</span>: git<span class="variable">@github</span>.<span class="attribute">com</span>:chaoge123456/chaoge123456.github.io.git  </span><br><span class="line">    <span class="attribute">coding</span>: git<span class="variable">@git</span>.coding.<span class="attribute">net</span>:chao3236gmailco/chao3236gmailco.git  </span><br><span class="line">  <span class="attribute">branch</span>: master</span><br></pre></td></tr></table></figure><p></p><p></p><h3>提交谷歌搜索引擎</h3><br><a href="https://www.google.com/webmasters/tools/home?hl=zh-CN" target="_blank" rel="noopener">Google搜索引擎提交入口</a><p></p><p></p><h3>提交百度搜索引擎</h3><br><a href="http://www.baidu.com/search/url_submit.htm" target="_blank" rel="noopener">百度搜索引擎入口</a><br>&emsp;&emsp;将站点地址提交给搜索引擎的步骤也比较简单，具体操作可以参考<a href="http://tengj.top/2016/03/14/hexo6seo/" target="_blank" rel="noopener">这篇博文</a><br>,这个过程中需要注意的问题是：<p></p><ul><li>将验证文件提交给站点时，有人会认为，直接将验证文件放入public文件夹中然后执行<strong>hexo g</strong>和<strong>hexo d</strong>就可以将验证文件提交的远程仓库。这样做确实可以将验证文件提交的远程仓库，但是需要注意的是此时的验证文件经过了hexo渲染，和原来的验证文件已经不一致，这样的验证文件时无效的</li><li>正确的做法是通过git clone获得远程仓库，在将验证文件加入刚刚获得的远程文件，然后通过向远程仓库提交该文件</li><li>验证完毕后，要向搜索引擎提交站点地图，方便爬虫爬取站点</li></ul><p></p><h2 id="end">总结</h2><br>&emsp;&emsp;HEXO+GITHUB+CODING博客搭建大概就是这些流程，希望大家看了我的博客会有所收获。这是我博客上的第一篇博文，确实不容易，希望以后能好好坚持下去吧。好了，夜已深了，晚安世界！<p></p>]]></content:encoded>
      
      <comments>https://chaoge123456.github.io/hex.html/#disqus_thread</comments>
    </item>
    
  </channel>
</rss>
